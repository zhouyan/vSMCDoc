\section{Basic usage}
\label{sec:Basic usage}

\subsection{Conventions}
\label{sub:Conventions}

All classes that are accessible to users are within the name space
\cppinline{vsmc}. Class names are in \cppinline{CamelCase} and function names,
free or class methods, are in \cppinline{small_cases}. In the remaining of this
guide, we will omit the \cppinline{vsmc::} name space qualifiers. We will use
``function'' for referring to name space scope functions and ``method'' for
class member functions.

\subsection{Getting and installing the library}
\label{sub:Getting and installing the library}

The library is hosted at
GitHub\footnote{\url{https://github.com/zhouyan/vSMC}}. This is a header only
\cpp template library. To install the library just move the contents of the
\shinline{include} directory into a proper place, e.g.,
\shinline{/usr/local/include} on Unix-alike systems. This library requires
working \cppoo, \blas and \lapack implementations. Standard C interface headers
for the later two (\cppinline{cblas.h} and \cppinline{lapacke.h}) are required.
Intel Threading Building
Blocks\footnote{\url{https://www.threadingbuildingblocks.org}} (\tbb), Intel
Math Kernel Library\footnote{\url{https://software.intel.com/en-us/intel-mkl}}
(\mkl) and \hdf\footnote{\url{http://www.hdfgroup.org}} are optional
third-party libraries. One need to define the configuration macros
\cppinline{VSMC_HAS_TBB}, \cppinline{VSMC_HAS_MKL} and
\cppinline{VSMC_HAS_HDF5} to nonzero values before including any \vsmc headers
to make their existence known to the library, respectively.

\subsection{Concepts}
\label{sub:Concepts}

\begin{table}[t]
  \begin{tabu}{X[l]X[2l]}
    \toprule
    Concept & Class \\
    \midrule
    State, $\{X^{(i)}\}_{i=1}^N$            & \texttt{T}, user defined   \\
    Weight, $\{W^{(i)}\}_{i=1}^N$           & \texttt{Weight}            \\
    Particle, $\{W^{(i)},X^{(i)}\}_{i=1}^N$ & \texttt{Particle<T>}       \\
    Single particle, $\{W^{(i)},X^{(i)}\}$  & \texttt{SingleParticle<T>} \\
    Sampler        & \texttt{Sampler<T>}                           \\
    Initialization & \texttt{Sampler<T>::init\_type}, user defined \\
    Move           & \texttt{Sampler<T>::move\_type}, user defined \\
    \mcmc          & \texttt{Sampler<T>::mcmc\_type}, user defined \\
    Monitor        & \texttt{Monitor<T>}                           \\
    \bottomrule
  \end{tabu}
  \caption{Core concepts of the library}
  \label{tab:concepts}
\end{table}

The library is structured around a few core concepts. A sampler is responsible
for running an algorithm. It is composed by a particle system and operations on
it. A particle system is formed by the states $\{X^{(i)}\}_{i=1}^N$ and weights
$\{W^{(i)}\}_{i=1}^N$. This system will also be responsible for resampling. All
user defined operations are to be applied to the whole system. These are
``initialization'' and ``moves'' which are applied before resampling, and
``\mcmc'' moves which are applied after resampling. These operations do not
have to be \mcmc kernels. They can be used for any purpose that suits the
particular algorithm. Most statistical inferences requires calculation of
$\sum_{i=1}^NW^{(i)}\varphi(X^{(i)})$ for some function $\varphi$. This can be
carried out along each sampler iteration by a monitor. Table~\ref{tab:concepts}
lists these concepts and the corresponding classes in the library. Each of them
are introduced in detail in the following sections.

\subsubsection{State}
\label{ssub:State}

The library gives users the maximum flexibility of how the states
$\{X^{(i)}\}_{i=1}^N$ shall be stored and structured. Any class type with a
constructor that takes a single integer value (the number of particles) as its
argument, and a method named \cppinline{copy} is acceptable. For example,
\begin{cppcode*}{texcomments}
  class State
  {
    public:
    State(std::size_t N);

    template <typename IntType>
    void copy(std::size_t N, IntType *index)
    {
      for (std::size_t i = 0; i != N; ++i) {
        // Let $a_i =$ index[i], set $X^{(i)} = X^{(a_i)}$
      }
    }
  };
\end{cppcode*}
How the state values are actually stored and accessed are entirely up to the
user.

For most applications, the states can be stored within an $N$ by $d$ matrix,
where $d$ is the dimension of the state. Let $X_{ij}$ denote the value of the
state of the $i$\ith particle at coordinate $j$. In this case, the library
provides a convenient class template,
\begin{cppcode}
  template <MatrixLayout Layout, std::size_t Dim, typename T>
  class StateMatrix;
\end{cppcode}
where \cppinline{Layout} is either \cppinline{RowMajor} or
\cppinline{ColMajor}, which specifies the matrix storage layout;
\cppinline{Dim} is a non-negative integer value. If \cppinline{Dim} is zero,
then the dimension may be changed at runtime. If it is positive, then the
dimension is fixed and cannot be changed at runtime. The last template
parameter \cppinline{T} is the \cpp type of $X_{ij}$. The following constructs
an object of this class,
\begin{cppcode}
  StateMatrix<ColMajor, Dynamic, double> sm(N);
\end{cppcode}
where \cppinline{Dynamic} is just an enumerator with value zero. We can specify
the dimension at runtime through the method \cppinline{sm.resize_dim(d)}. Note
that, if the template parameter \cppinline{Dim} is positive, then this call
results in a compile-time error. To access $X_{ij}$, one can call the method
\cppinline{sm.state(i, j)}. The method \cppinline{sm.data()} returns a pointer
to the beginning of the matrix. If \cppinline{Layout} is \cppinline{RowMajor},
then the method \cppinline{sm.row_data(i)} returns a pointer to the beginning
of $i$\ith row. If \cppinline{Layout} is \cppinline{ColMajor}, then the method
\cppinline{sm.col_data(j)} returns a pointer to the begninning of $j$\ith
column. These methods facilitate the interfacing with numerical libraries, such
as \blas.

The \cppinline{StateMatrix} class deliberately does not provide a
\cppinline{resize} method. There are algorithms that change the sample size
between iterations. However, such algorithms often change size through
resampling or other methods, either deterministically or stochastically. A
\cppinline{resize} method is of little use in the context of \smc algorithms
but inviting errors. These possible errors do not introduce runtime issues such
as memory leak, but they break the integrity of the data structure
statistically. An example of changing size of a sampler is provided in
section~\ref{sub:Resizing a sampler}.

\subsubsection{Weight}
\label{ssub:Weight}

The weights $\{W^{(i)}\}_{i=1}^N$ are abstracted by the \cppinline{Weight}
class. The following constructs an object of this class,
\begin{cppcode}
  Weight w(N);
\end{cppcode}
There are a few methods for accessing the weights,
\begin{cppcode*}{texcomments}
  w.ess();          // Get {\normalfont\textsc{ess}}
  w.set_equal();    // Set $W^{(i)} = 1/N$
\end{cppcode*}
To mutate the weights through an input iterator, say \cppinline{v},
\begin{cppcode*}{texcomments}
  w.set(v);         // Set $W^{(i)} \propto v^{(i)}$
  w.mul(v);         // Set $W^{(i)} \propto W^{(i)} v^{(i)}$
  w.set_log(v);     // Set $\log W^{(i)} = v^{(i)} + \text{const.}$
  w.add_log(v);     // Set $\log W^{(i)} = \log W^{(i)} + v^{(i)} + \text{const.}$
\end{cppcode*}
The iterator will be advanced $N$ times. Alternatively, one can also mutate the
weights through a random access iterator, say \cppinline{v}, and a positive
stride \cppinline{k},
\begin{cppcode*}{texcomments}
  w.set(v, k);      // Set $W^{(i)} \propto v^{(ik)}$
  w.mul(v, k);      // Set $W^{(i)} \propto W^{(i)} v^{(ik)}$
  w.set_log(v, k);  // Set $\log W^{(i)} = v^{(ik)} + \text{const.}$
  w.add_log(v, k);  // Set $\log W^{(i)} = \log W^{(i)} + v^{(ik)} + \text{const.}$
\end{cppcode*}
The iterator will be advanced $N$ times, each time by $k$ steps. The method
\cppinline{w.data()} returns a pointer to the normalized weights. It is
important to note that the weights are always normalized and all mutable
methods only allow access to $\{W^{(i)}\}_{i=1}^N$ as a whole.

\subsubsection{Particle}
\label{ssub:Particle}

A particle system is composed of both the state values, which is of user
defined type, say \cppinline{T}, and the weights. The following constructs an
object of class \cppinline{Particle<T>},
\begin{cppcode}
  Particle<T> particle(N);
\end{cppcode}
The method \cppinline{particle.value()} returns the type \cppinline{T} object,
and \cppinline{particle.weight()} returns the type \cppinline{Weight} object.
They are constructed with the same integer value $N$ when the above constructor
is invoked.

As a Monte Carlo algorithm, random number generators (\rng) will be used
frequently. The user is free to use whatever \rng mechanism as they see fit.
However, one common issue encountered in practice is how to maintain
independence of the \rng streams between function calls. For example, consider
below a function that manipulates some state values,
\begin{cppcode}
  void function(double &x)
  {
    std::mt19937 rng;
    std::normal_distribution<double> rnorm;
    x = rnorm(rng);
  }
\end{cppcode}
Every call of this function will give \cppinline{x} exactly the same value.
This is hardly what the user intended. One might consider an global \rng or one
as class member data. For example,
\begin{cppcode}
  std::mt19937 rng;
  void function(double &x)
  {
    std::normal_distribution<double> rnorm;
    x = rnorm(rng);
  }
\end{cppcode}
This will work fine as long as the function is never called by two threads at
the same time. However, \smc algorithms are natural candidates to
parallelization. Therefore, the user will need to either lock the \rng, which
degenerates the performance, or construct different \rng{}s for different
threads. The later, though ensures thread-safety, has other issues. For
example, consider
\begin{cppcode}
  std::mt19937 rng1(s1); // For thread 1
  std::mt19937 rng2(s2); // For thread 2
\end{cppcode}
where the seeds $s_1 \ne s_2$. It is difficult to ensure that the two streams
generated by the two \rng{}s are independent. Common practice for parallel \rng
is to use sub-streams or leap-frog algorithms. Without going into any further
details, it is sufficient to say that this is perhaps not a problem that most
users bother to solve.

The library provides a simple solution to this issue. The method
\cppinline{particle.rng(i)} returns a reference to an \rng that conforms to the
\cppoo uniform \rng concept. It can be called from different threads at the
same time, for example,
\begin{cppcode}
  particle.rng(i); // Call from thread i
  particle.rng(j); // Call from thread j
\end{cppcode}
If $i \ne j$, then the above calls are guaranteed to be thread-safe. If \tbb is
available to the library, then it is also thread-safe even if $i = j$. In
addition, each instance of the \rng generates independent streams. Therefore,
one can write functions that process each particle, for example,
\begin{cppcode}
  void function(std::size_t i)
  {
    auto &rng = particle.rng(i);
    // Process particle i using rng
  }
\end{cppcode}
The details of the \rng system are documented later in section~\ref{sec:Random
  number generating}.

\subsubsection{Single particle}
\label{ssub:Single particle}

It is often easier to define a function $f(X^{(i)})$ than
$f(X^{(1)},\dots,X^{(N)})$. However, \cppinline{Particle<T>} only provides
access to $\{X^{(i)}\}_{i=1}^N$ as a whole through
\cppinline{particle.value()}. To allow direct access to $X^{(i)}$, the library
uses a class template \cppinline{SingeParticle<T>}. An object of this class is
constructed from the index $i$ of the particle, and a pointer to the particle
system it belongs to, for example,
\begin{cppcode}
  SingleParticle<T> sp(i, &particle);
\end{cppcode}
or more conveniently,
\begin{cppcode}
  auto sp = particle.sp(i);
\end{cppcode}
In its most basic form, it has the following methods,
\begin{cppcode}
  sp.id();       // Get the value i that sp was constructed with
  sp.particle(); // A reference to the Particle<T> object
  sp.rng();      // => sp.particle().rng(sp.id());
\end{cppcode}
If \cppinline{T} is a subclass of \cppinline{StateMatrix}, then it has two
additional methods,
\begin{cppcode}
  sp.dim();    // => sp.particle().value().dim();
  sp.state(j); // => sp.particle().value().state(sp.id(), j);
\end{cppcode}
It is clear now that the interface of \cppinline{SingleParticle<T>} depends on
the type \cppinline{T}. Later in section~\ref{sub:Customizing SingleParticle}
we will show how to insert additional methods into this class.

\subsubsection{Sampler}
\label{ssub:Sampler}

A sampler can be constructed in a few ways,
\begin{cppcode}
  Sampler<T> sampler(N);
\end{cppcode}
constructs a sampler that is never resampled, while
\begin{cppcode}
  Sampler<T> sampler(N, Multinomial);
\end{cppcode}
constructs a sampler that is resampled every iteration, using the multinomial
method. Other resampling schemes are also possible, see
section~\ref{sec:Resampling}. Last, one can also construct a sampler that is
only resampled when $\ess < \alpha N$, $\alpha\in[0, 1]$, by the following,
\begin{cppcode}
  Sampler<T> sampler(N, Multinomial, alpha);
\end{cppcode}
In summary, if one does not tell the constructor which resampling scheme to
use, then it is assumed one does not want to do resampling. If one specify the
resampling scheme without a threshold for \ess, then it is assumed it need to
be done at every step. More advanced constructors will be discussed in
section~\ref{sec:Resampling}

The method \cppinline{sampler.particle()} returns a reference to the particle
system. A sampler can be initialized by user defined object that is convertible
to the following type,
\begin{cppcode}
  using init_type = std::function<std::size_t(Particle<T> &, void *)>;
\end{cppcode}
For example,
\begin{cppcode}
  auto init = [](Particle<T> &particle, void *param) { /* Process particle /*};
\end{cppcode}
is a \cppoo lambda expression that can be used for this purpose. One can add it
to a sampler by calling \cppinline{sampler.init(init)}. Upon calling
\cppinline{sampler.initialize(param)}, the user defined function
\cppinline{init} will be called and the argument \cppinline{param} will be
passed to it.

Similarly, after initialization, at each iteration, the particle system can be
manipulated by users given callable objects that is convertible to the
following types,
\begin{cppcode}
  using move_type = std::function<std::size_t(std::size_t, Particle<T> &)>;
  using mcmc_type = std::function<std::size_t(std::size_t, Particle<T> &)>;
\end{cppcode}
Multiple moves can be added to a sampler. The call
\cppinline{sampler.move(move, append)} adds a \cppinline{move_type} object to
the sampler, where \cppinline{append} is a boolean value. If it is
\cppinline{false}, the call will clear any moves that were added before. If it
is \cppinline{true}, then \cppinline{move} is appended to the end of a sequence
of moves. Each move will be called one by one upon calling
\cppinline{sampler.iterate()}. A similar sequence of \mcmc moves can also be
added to a sampler. The call \cppinline{sampler.iterate()} will call user
defined moves first, then perform the possible resampling, and then the
sequence of \mcmc moves.

Note that the possible resampling will also be performed after the user defined
initialization function is called by \cppinline{sampler.initialize(param)}. And
after it, the sequence of \mcmc moves will be called. If it desired no to
perform mutations during initialization, then following can be used,
\begin{cppcode}
  sampler.init(init);
  sampler.initialize(param);
  sampler.move(move, true).mcmc(mcmc, true);
  sampler.iterate(n);
\end{cppcode}
The above snippet code also demonstrates that most methods of
\cppinline{Sampler<T>} return a reference to the sampler itself and thus method
calls can be chained. In addition, method \cppinline{sampler.iterate(n)}
accepts an optional argument that specifies the number of iterations. It is a
shortcut for
\begin{cppcode}
  for (std::size_t i = 0; i != n; ++i)
  sampler.iterate();
\end{cppcode}

\subsubsection{Monitor}
\label{ssub:Monitor}

Inferences using a \smc algorithm usually require the calculation of the
quantity $\sum_{i=1}^NW^{(i)}\varphi(X^{(i)})$ at each iteration. One can
define callable object that is convertible to
\begin{cppcode}
  using eval_type =
  std::function<void(std::size_t, std::size_t, Particle<T> &, double *);
\end{cppcode}
For example,
\begin{cppcode*}{texcomments}
  void eval(std::size_t iter, std::size_t d, Particle<T> &particle, double *r)
  {
    for (std::size_t i = 0; i != particle.size(); ++i, r += dim) {
      auto sp = particle.sp(i);
      r[0] = /* $\varphi_1(X^{(i)})$ */;
      // ...
      r[d - 1] = /* $\varphi_d(X^{(i)})$ */;
    }
  }
\end{cppcode*}
The argument \cppinline{d} is the dimension of the vector function $\varphi$.
The output is an $N$ by $d$ matrix, with each row corresponding to the value of
$\varphi(X^{(i)})$. Then one can add this function to a sampler by calling,
\begin{cppcode}
  sampler.monitor("name", d, eval);
\end{cppcode}
where the first argument is the name for the monitor, second its dimension, and
the third the evaluation function. Then after all the initialization, possible
resampling, moves and \mcmc moves are done, the sampler will calculate
$\sum_{i=1}^NW^{(i)}\varphi(X^{(i)})$. This method has two optional arguments.
First is a boolean value \cppinline{record_only}. If it is \cppinline{true}, it
is assumed that no summation is needed. For example,
\begin{cppcode*}{texcomments}
  void eval(std::size_t iter, std::size_t d, Particle<T> &particle, double *r)
  {
    r[0] = /* $\varphi_1(\{X^{(i)}\}_{i=1}^N)$ */;
    // ...
    r[d - 1] = /* $\varphi_d(\{X^{(i)}\}_{i=1}^N)$ */;
  }
\end{cppcode*}
In this case, the monitor acts merely as a storage facility. The second
optional argument is \cppinline{stage} which specifies at which point the
monitoring shall happen. It can be \cppinline{MonitorMove}, which specifies
that the monitoring happens right after the moves and before resampling. It can
also be \cppinline{MonitorResample}, which specifies that the monitoring
happens right after the resampling and before the \mcmc moves. Last, the
default is \cppinline{MonitorMCMC}, which specifies that the monitoring happens
after everything.

The output of a sampler, together with the records of any monitors it has can
be output in plain text forms through a \cpp output stream. For example,
\begin{cppcode}
  std::cout << sampler;
\end{cppcode}
We will see how this works later with a concrete particle filter example. If
the \hdf library is available, it is also possible to write such output to \hdf
format, for example,
\begin{cppcode}
  hdfstore(sampler, file_name, data_name);
\end{cppcode}
Details can be found in section~\ref{sub:Storing objects in hdf}.

\subsection{A simple particle filter}
\label{sub:A simple particle filter}

\subsubsection{Model and algorithm}
\label{ssub:Model and algorithm}

This is an example used in \textcite{Johansen:2009wd}. Through this example, we
will show how to re-implement a simple particle filter in \vsmc. It shall walk
one through the basic features of the library introduced above.

The state space model, known as the almost constant velocity model in the
tracking literature, provides a simple scenario. The state vector $X_t$
contains the position and velocity of an object moving in a plane. That is,
$X_t = (\xpos^t, \ypos^t, \xvel^t, \yvel^t)^T$. Imperfect observations $Y_t =
(\xobs^t, \yobs^t)^T$ of the positions are possible at each time instance. The
state and observation equations are linear with additive noises,
\begin{align*}
  X_t &= AX_{t-1} + V_t \\
  Y_t &= BX_t + \alpha W_t
\end{align*}
where
\begin{equation*}
  A = \begin{pmatrix}
    1 & \Delta & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix} \qquad
  B = \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
  \end{pmatrix} \qquad
  \alpha = 0.1
\end{equation*}
and we assume that the elements of the noise vector $V_t$ are independent
Gaussian with variance $0.02$ and $0.001$ for position and velocity,
respectively. The observation noise, $W_t$ comprises independent, identically
distributed $t$-distributed random variables with degree of freedom $\nu = 10$.
The prior at time $0$ corresponds to an axis-aligned Gaussian with variance $4$
for the position coordinates and $1$ for the velocity coordinates. The particle
filter algorithm is shown in algorithm~\ref{alg:pf}.

\begin{algorithm}[t]
  \begin{algorithmic}
    \hrule\vskip1ex
    \STATE \emph{Initialization}
    \STATE\STATESKIP Set $t\leftarrow0$.
    \STATE\STATESKIP Sample
    $\xpos^{(0,i)},\ypos^{(0,i)}\sim\calN(0,4)$ and
    $\xvel^{(0,i)},\yvel^{(0,i)}\sim\calN(0,1)$.
    \STATE\STATESKIP Weight $W_0^{(i)} \propto \exp{\ell(X_0^{(i)}|Y_0)}$ where
    $\ell$ is the likelihood function.

    \STATE \emph{Iteration}
    \STATE\STATESKIP Set $t\leftarrow t + 1$.
    \STATE\STATESKIP Sample
    \begin{align*}
      \xpos^{(t,i)}&\sim\calN(\xpos^{(t-1,i)} + \Delta\xvel^{(t-1,i)}, 0.02) &
      \xvel^{(t,i)}&\sim\calN(\xvel^{(t-1,i)}, 0.001) \\
      \ypos^{(t,i)}&\sim\calN(\ypos^{(t-1,i)} + \Delta\yvel^{(t-1,i)}, 0.02) &
      \yvel^{(t,i)}&\sim\calN(\yvel^{(t-1,i)}, 0.001)
    \end{align*}
    \STATE\STATESKIP Weight $W_t^{(i)} \propto
    W_{t-1}^{(i)}\exp{\ell(X_t^{(i)}|Y_t)}$.

    \STATE \emph{Repeat the \emph{Iteration} step until all data are processed}.
    \vskip1ex\hrule
  \end{algorithmic}
  \caption{Particle filter algorithm for the almost constant velocity model.}
  \label{alg:pf}
\end{algorithm}

\subsubsection{Implementations}
\label{ssub:Implementations}

We first show the main program.
\cppfile{pf.cpp}

A \cppinline{Sampler<PFState>} object is constructed first. Then the
initialization \cppinline{PFInit}, move \cppinline{PFMove} and a monitor
\cppinline{PFMEval} that records $\xpos^t$ and $\ypos^t$ are added to the
sampler. The monitor is named \cppinline{"pos"}. Then it is initialized with
the name of the data file \shinline{"pf.data"}, and iterated $n - 1$ times,
where $n$ is the number of data points. At last, the output is written into a
text file \shinline{"pf.out"}. Below is a short
R\footnote{\url{http://r-project.org}} script that can be used to process this
\rfile{pf.R}

The \rinline{print} statement shows the first five lines of the output,
\routfile{pf.rout}

The column \routinline{Size} shows the sample size at each iteration. The
library does not provide direct support of changing the sample size. However,
it is possible and an example is shown in section~\ref{sec:Resampling}. The
column \routinline{Resampled} shows nonzero values if resampling were performed
and zero otherwise. For each moves and \mcmc steps, an acceptance count will be
recorded. In this particular example, it is irrelevant. Next the column
\routinline{ESS} shows the value of \ess. The last two columns show the
importance sampling estimates of the positions recorded by the monitor named
\cppinline{"pos"}. The graphical representation of the output is shown in
figure~\ref{fig:pf}.

\begin{figure}
  \includegraphics{pf}
  \caption{A simple particle system}
  \label{fig:pf}
\end{figure}

Before diving into the details of the implementation of \cppinline{PFState},
etc., we will first define a few constant. The state space is of dimension $4$.
And it is natural to use a \cppinline{StateMatrix} as the base class of
\cppinline{PFState}. We define the following constants as the indices of each
state component.
\cppfile{pf_const.hpp}

\paragraph{State: \texttt{PFState}}

As noted earlier, \cppinline{StateMatrix} will be used as the base class of
\cppinline{PFState}. Since the data will be shared by all particles, we also
store the data within this class. And methods will be provided to read the data
from an external file, and compute the log-likelihood $\ell(X^{(i)})$, which
accesses the data. Below the definition of the class \cppinline{PFState}
\cppfile{pf_state.hpp}

The method \cppinline{log_likelihood} accepts the iteration number (starting
from zero at initialization) and the particle number as its input. It returns
the value of $\ell(X^{(i)})$. The method \cppinline{read_data} read the data
input member data.

\paragraph{Initialization: \texttt{PFInit}}

The initialization step is implemented as below.
\cppfile{pf_init.hpp}

An object of this class is convertible to
\cppinline{Sampler<PFState>::init_type}. After initialization each state
component with the respective Gaussian distribution, we compute the
log-likelihood and store them in a vector. The class template
\cppinline{vsmc::Vector} is very similar to \cppinline{std::vector}. See
section~\ref{sub:Aligned memory allocation} for details. After all particles
have been initialized, we set the weights of the system.

The main method, \cppinline{operator()} calls a few other methods to perform
the tasks. Later in section~\ref{sub:Symmetric Multiprocessing} it will become
clear why we structured the implementation this way.

\paragraph{Move: \texttt{PFMove}}

The move step is similar to the initialization. The implementation is as below,
\cppfile{pf_move.hpp}

\paragraph{Monitor: \texttt{PFMEval}}

Last we define \cppinline{PFMEval}, which simply copies the values of the
positions.
\cppfile{pf_meval.hpp}

\subsection{Symmetric Multiprocessing}
\label{sub:Symmetric Multiprocessing}

The above example is implemented in a sequential fashion. However, the loops
inside \cppinline{PFInit}, \cppinline{PFMove} and \cppinline{PFMEval} clearly
can be parallelized. The library provides basic support of multicore
parallelization through its \smp module. Two widely used backends, OpenMP and
\tbb are available. Here we demonstrate how to use the \tbb backend. First we
will declare the implementation classes as subclasses as below,
\begin{cppcode}
  class PFInit : public InitializationTBB<PFState>;
  class PFMove : public MoveTBB<PFState>;
  class PFMEval : public MonitorEvalTBB<PFState>;
\end{cppcode}
And remove \cppinline{operator()} from their implementations. After these
changes, the implementation will be parallelized using \tbb. It works as if
\cppinline{InitializationTBB<PFState>} has an implementation of
\cppinline{operator()} as we did before, except it is parallelized. Now it is
clear that, method such as \cppinline{eval_pre} and \cppinline{eval_post} are
called before and after the main loop. Method \cppinline{eval_sp} is called
within the loop and it need to be thread-safe. This is the main reason we
constructed the \cppinline{NormalDistribution} objects within
\cppinline{eval_sp} instead of as member data, even though they are constructed
in exactly the same way for each particle. This is because
\cppinline{NormalDistribution::operator()} is a mutable method and thus not
thread-safe.

If any of these member functions does not do anything, then it does not have to
be defined in the derived class. For example, \cppinline{PFMEval} can be
simplified to
\cppfile{pf_meval_tbb.hpp}

Apart from the three base classes we have shown here, there are also
\cppinline{InitializationOMP}, etc., for using the OpenMP backend. And
\cppinline{InitializationSEQ}, etc., for implementation without
parallelization. The later works in exactly the same way as our implementation
in the last section. It is often easier to debug a single-threaded program than
a parallelized one. And thus one may develop the algorithm with the sequential
backend and obtain optimal performance latter by only changing the name of a
few base class names. This can usually be done automatically through a build
system.

The complete implementation of a parallelized sampler is shown in the following
pages.
\cppfile{pf_state_tbb.hpp}
\cppfile{pf_init_tbb.hpp}
\cppfile{pf_move_tbb.hpp}
\cppfile{pf_meval_tbb.hpp}

\subsubsection{Performance consideration}
\label{sub:Performance consideration}

The base classes dispatch calls to \cppinline{eval_pre}, \cppinline{eval_sp},
etc., through the virtual function mechanism. The performance impact is minimal
for \cppinline{eval_pre} and \cppinline{eval_post}, since they are called only
once in each iteration and we expect the computational cost will be dominated
by \cppinline{eval_sp} in most cases. However, the dynamic dispatch can cause
considerable performance degenerating if the cost of a single call to
\cppinline{eval_sp} is small while the number of particles is large. Modern
optimizing compilers can usually devirtualize the method calls in trivial
situations. However, it is not always possible. In this situation, the library
will need a little help from the user to make compile-time dispatch. For each
implementation class, we will declare it in the following way,
\begin{cppcode}
  class PFInit : public InitializationTBB<PFState, PFInit>;
  class PFMove : public MoveTBB<PFState, PFMove>;
  class PFMEval : public MonitorEvalTBB<PFState, PFMEval>;
\end{cppcode}
The second template argument of the base class need to be exactly the same as
the derived class. For interested users, this is called Curiously Recurring
Template Pattern%
\footnote{\url{https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern}}
(\crtp). This usage of the library's base classes also provides other
flexibility. The methods \cppinline{eval_pre} etc., can be either
\cppinline{const} or mutable. They can also be \cppinline{static}.
