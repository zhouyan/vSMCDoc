\documentclass[11pt,bib,mint,hyper,altcolor]{marticle}

\addbibresource{user_guide.bib}
\newlength\fixedchar
\settowidth{\fixedchar}{\texttt{\normalsize 0}}
\geometry{textwidth=80\fixedchar}

\NewMinted{cmake}
\NewMinted{console}
\NewMinted{cpp}
\NewMinted{rout}
\NewMinted{r}
\NewMinted{sh}

\UseAbbr{ais}
\UseAbbr{api}
\UseAbbr{avx}
\UseAbbr{blas}
\UseAbbr{brng}
\UseAbbr{cpu}
\UseAbbr{crtp}
\UseAbbr{ess}
\UseAbbr{gpu}
\UseAbbr{lapack}
\UseAbbr{mcmc}
\UseAbbr{mkl}
\UseAbbr{mpi}
\UseAbbr{pdf}
\UseAbbr{raii}
\UseAbbr{rdrand}
\UseAbbr{rng}
\UseAbbr{simd}
\UseAbbr{sis}
\UseAbbr{smctc}
\UseAbbr{smc}
\UseAbbr{smp}
\UseAbbr{sse}
\UseAbbr{tbb}
\UseAbbr{tls}

\UseAbbr[\aesni][\textsc]{aes-ni}
\UseAbbr[\cpp][\textcase]{C++}
\UseAbbr[\cppoo][\lnfigures\textcase]{C++11}
\UseAbbr[\hdf]{hdf5}
\UseAbbr[\ith][\textsups]{t{}h}
\UseAbbr[\vsmc][]{vSMC}

\UseMathCal{N}

\def\xobs{X_{\mathrm{obs}}}
\def\xpos{X_{\mathrm{pos}}}
\def\xvel{X_{\mathrm{vel}}}
\def\yobs{Y_{\mathrm{obs}}}
\def\ypos{Y_{\mathrm{pos}}}
\def\yvel{Y_{\mathrm{vel}}}
\def\STATESKIP{\hskip.68cm}
\def\spt{\texttt{SingleParticle<T>}}
\def\version{develop}

\begin{document}

\title{\protect\vsmc{} -- Parallel Sequential Monte Carlo in \protect\cpp}
\author{Yan Zhou}
\date{Version \version}

\maketitle
\tableofcontents

\begin{abstract}
  Sequential Monte Carlo is a family of algorithms for sampling from a sequence
  of distributions. Some of these algorithms, such as particle filters, are
  widely used in the physics and signal processing researches. More recent
  developments have established their application in more general inference
  problems such as Bayesian modeling.

  These algorithms have attracted considerable attentions in recent years as
  they admit natural and scalable parallelization. However, these algorithms
  are perceived to be difficult to implement. In addition, parallel programming
  is often unfamiliar to many researchers though conceptually appealing,
  especially for sequential Monte Carlo related fields. A \cpp template library
  is presented for the purpose of implementing general sequential Monte Carlo
  algorithms on parallel hardware.
\end{abstract}

\section{Introduction}
\label{sec:Introduction}

Sequential Monte Carlo (\smc) methods are a class of sampling algorithms that
combine importance sampling and resampling. They have been primarily used as
``particle filters'' to solve optimal filtering problems; see, for example,
\textcite{Cappe:2007hz} and \textcite{Doucet:2011us} for recent reviews. They
are also used in a static setting where a target distribution is of interest,
for example, for the purpose of Bayesian modeling. This was proposed by
\textcite{DelMoral:2006hc} and developed by \textcite{Peters:2005wh} and
\textcite{DelMoral:2006wv}. This framework involves the construction of a
sequence of artificial distributions on spaces of increasing dimensions which
admit the distributions of interest as particular marginals.

\smc algorithms are perceived as being difficult to implement while general
tools were not available until the development of \smctc by
\textcite{Johansen:2009wd}, which provided a general framework for implementing
\smc algorithms. \smc algorithms admit natural and scalable parallelization.
However, there are only parallel implementations of \smc algorithms for many
problem specific applications, usually associated with specific \smc related
researches. \textcite{Lee:2010fm} studied the parallelization of \smc
algorithms on \gpu{}s with some generality. There are few general tools to
implement \smc algorithms on parallel hardware though multicore \cpu{}s are
very common today and computing on specialized hardware such as \gpu{}s are
more and more popular.

The purpose of the current work is to provide a general framework for
implementing \smc algorithms on both sequential and parallel hardware. There
are two main goals of the presented framework. The first is reusability. It
will be demonstrated that the same implementation source code can be used to
build a serialized sampler, or using different programming models (for example,
OpenMP and Intel Threading Building Blocks) to build parallelized samplers for
multicore \cpu{}s. The second is extensibility. It is possible to write a
backend for \vsmc to use new parallel programming models while reusing existing
implementations. It is also possible to enhance the library to improve
performance for specific applications. Almost all components of the library can
be reimplemented by users and thus if the default implementation is not
suitable for a specific application, they can be replaced while being
integrated with other components seamlessly.

Section~\ref{sec:Sequential Monte Carlo} introduces the \smc algorithm and
notations used throughout this guide. Section~\ref{sec:Basic usage} introduces
the basic features of the library. It is followed by section~\ref{sec:Advanced
  usage}, which details a few more advanced usage of the library.
Section~\ref{sec:Mathemtical operations} to~\ref{sec:Utilities} introduces some
useful additional features. It is not practical and of little interest to the
users to include all the details of the library in this guide. A
Doxygen\footnote{\url{http://www.stack.nl/~dimitri/doxygen/}} generated
reference manual can be access
online\footnote{\url{http://zhouyan.github.io/vSMCDoc/\version/}}.

\section{Sequential Monte Carlo}
\label{sec:Sequential Monte Carlo}

\subsection{Sequential importance sampling and resampling}
\label{sub:Sequential importance sampling and resampling}

Importance sampling is a technique which allows the calculation of the
expectation of a function $\varphi$ with respect to a distribution $\pi$ using
samples from some other distribution $\eta$ with respect to which $\pi$ is
absolutely continuous, based on the identity,
\begin{equation}
  \Exp_{\pi}[\varphi(X)]
  = \int\varphi(x)\pi(x)\intd x
  = \int\frac{\varphi(x)\pi(x)}{\eta(x)}\eta(x)\intd x
  = \Exp_{\eta}\Square[Big]{\frac{\varphi(X)\pi(X)}{\eta(X)}}
\end{equation}
And thus, let $\{X^{(i)}\}_{i=1}^N$ be samples from $\eta$, then
$\Exp_{\pi}[\varphi(X)]$ can be approximated by
\begin{equation}
  \hat\varphi_1 =
  \frac{1}{N}\sum_{i=1}^N\frac{\varphi(X^{(i)})\pi(X^{(i)})}{\eta(X^{(i)})}
\end{equation}
In practice $\pi$ and $\eta$ are often only known up to some normalizing
constants, which can be estimated using the same samples. Let $w^{(i)} =
\pi(X^{(i)})/\eta(X^{(i)})$, then we have
\begin{equation}
  \hat\varphi_2 =
  \frac{\sum_{i=1}^Nw^{(i)}\varphi(X^{(i)})}{\sum_{i=1}^Nw^{(i)}}
\end{equation}
or
\begin{equation}
  \hat\varphi_3 = \sum_{i=1}^NW^{(i)}\varphi(X^{(i)})
\end{equation}
where $W^{(i)}\propto w^{(i)}$ and are normalized such that
$\sum_{i=1}^NW^{(i)} = 1$.

Sequential importance sampling (\sis) generalizes the importance sampling
technique for a sequence of distributions $\{\pi_t\}_{t\ge0}$ defined on spaces
$\{\prod_{k=0}^tE_k\}_{t\ge0}$. At time $t = 0$, sample $\{X_0^{(i)}\}_{i=1}^N$
from $\eta_0$ and compute the weights $W_0^{(i)} \propto
\pi_0(X_0^{(i)})/\eta_0(X_0^{(i)})$. At time $t\ge1$, each sample
$X_{0:t-1}^{(i)}$, usually termed \emph{particles} in the literature, is
extended to $X_{0:t}^{(i)}$ by a proposal distribution
$q_t(\cdot|X_{0:t-1}^{(i)})$. And the weights are recalculated by $W_t^{(i)}
\propto \pi_t(X_{0:t}^{(i)})/\eta_t(X_{0:t}^{(i)})$ where
\begin{equation}
  \eta_t(X_{0:t}^{(i)}) =
  \eta_{t-1}(X_{0:t-1}^{(i)})q_t(X_{0:t}^{(i)}|X_{0:t-1}^{(i)})
\end{equation}
and thus
\begin{align}
  W_t^{(i)} \propto \frac{\pi_t(X_{0:t}^{(i)})}{\eta_t(X_{0:t}^{(i)})}
  &= \frac{\pi_t(X_{0:t}^{(i)})\pi_{t-1}(X_{0:t-1}^{(i)})}
  {\eta_{t-1}(X_{0:t-1}^{(i)})q_t(X_{0:t}^{(i)}|X_{0:t-1}^{(i)})
    \pi_{t-1}(X_{0:t-1}^{(i)})} \notag\\
  &= \frac{\pi_t(X_{0:t}^{(i)})}
  {q_t(X_{0:t}^{(i)}|X_{0:t-1}^{(i)})\pi_{t-1}(X_{0:t-1}^{(i)})}W_{t-1}^{(i)}
  \label{eq:si}
\end{align}
and importance sampling estimate of $\Exp_{\pi_t}[\varphi_t(X_{0:t})]$ can be
obtained using $\{W_t^{(i)},X_{0:t}^{(i)}\}_{i=1}^N$.

However this approach fails as $t$ becomes large. The weights tend to become
concentrated on a few particles as the discrepancy between $\eta_t$ and $\pi_t$
becomes larger. Resampling techniques are applied such that, a new particle
system $\{\bar{W}_t^{(i)},\bar{X}_{0:t}^{(i)}\}_{i=1}^M$ is obtained with the
property,
\begin{equation}
  \Exp\Square[Big]{\sum_{i=1}^M\bar{W}_t^{(i)}\varphi_t(\bar{X}_{0:t}^{(i)})} =
  \Exp\Square[Big]{\sum_{i=1}^NW_t^{(i)}\varphi_t(X_{0:t}^{(i)})}
  \label{eq:resample}
\end{equation}
In practice, the resampling algorithm is usually chosen such that $M = N$ and
$\bar{W}^{(i)} = 1/N$ for $i=1,\dots,N$. Resampling can be performed at each
time $t$ or adaptively based on some criteria of the discrepancy. One popular
quantity used to monitor the discrepancy is \emph{effective sample size}
(\ess), introduced by \textcite{Liu:1998iu}, defined as
\begin{equation}
  \ess_t = \frac{1}{\sum_{i=1}^N (W_t^{(i)})^2}
\end{equation}
where $\{W_t^{(i)}\}_{i=1}^N$ are the normalized weights. And resampling can be
performed when $\ess\le \alpha N$ where $\alpha\in[0,1]$.

The common practice of resampling is to replicate particles with large weights
and discard those with small weights. In other words, instead of generating a
random sample $\{\bar{X}_{0:t}^{(i)}\}_{i=1}^N$ directly, a random sample of
integers $\{R^{(i)}\}_{i=1}^N$ is generated, such that $R^{(i)} \ge 0$ for $i =
1,\dots,N$ and $\sum_{i=1}^N R^{(i)} = N$. And each particle value
$X_{0:t}^{(i)}$ is replicated for $R^{(i)}$ times in the new particle system.
The distribution of $\{R^{(i)}\}_{i=1}^N$ shall fulfill the requirement of
Equation~\eqref{eq:resample}. One such distribution is a multinomial
distribution of size $N$ and weights $(W_t^{(i)},\dots,W_t^{(N)})$. See
\textcite{Douc:2005wa} for some commonly used resampling algorithms.

\subsection{\protect\smc samplers}
\label{sub:SMC Samplers}

\smc samplers allow us to obtain, iteratively, collections of weighted samples
from a sequence of distributions $\{\pi_t\}_{t\ge0}$ over essentially any
random variables on some spaces $\{E_t\}_{t\ge0}$, by constructing a sequence
of auxiliary distributions $\{\tilde\pi_t\}_{t\ge0}$ on spaces of increasing
dimensions, $\tilde\pi_t(x_{0:t})=\pi_t (x_t) \prod_{s=0}^{t-1}
L_s(x_{s+1},x_s)$, where the sequence of Markov kernels $\{L_s\}_{s=0}^{t-1}$,
termed backward kernels, is formally arbitrary but critically influences the
estimator variance. See \textcite{DelMoral:2006hc} for further details and
guidance on the selection of these kernels.

Standard sequential importance sampling and resampling algorithms can then be
applied to the sequence of synthetic distributions, $\{\tilde\pi_t\}_{t\ge0}$.
At time $t - 1$, assume that a set of weighted particles
$\{W_{t-1}^{(i)},X_{0:t-1}^{(i)}\}_{i=1}^N$ approximating $\tilde\pi_{t-1}$ is
available, then at time $t$, the path of each particle is extended with a
Markov kernel say, $K_t(x_{t-1}, x_t)$ and the set of particles
$\{X_{0:t}^{(i)}\}_{i=1}^N$ reach the distribution $\eta_t(X_{0:t}^{(i)}) =
\eta_0(X_0^{(i)})\prod_{k=1}^tK_t(X_{t-1}^{(i)}, X_t^{(i)})$, where $\eta_0$ is
the initial distribution of the particles. To correct the discrepancy between
$\eta_t$ and $\tilde\pi_t$, Equation~\eqref{eq:si} is applied and in this case,
\begin{equation}
  W_t^{(i)} \propto \frac{\tilde\pi_t(X_{0:t}^{(i)})}{\eta_t(X_{0:t}^{(i)})}
  = \frac{\pi_t(X_t^{(i)})\prod_{s=0}^{t-1}L_s(X_{s+1}^{(i)}, X_s^{(i)})}
  {\eta_0(X_0^{(i)})\prod_{k=1}^tK_t(X_{t-1}^{(i)},X_t^{(i)})}
  \propto \tilde{w}_t(X_{t-1}^{(i)}, X_t^{(i)})W_{t-1}^{(i)}
\end{equation}
where $\tilde{w}_t$, termed the \emph{incremental weights}, are calculated as,
\begin{equation}
  \tilde{w}_t(X_{t-1}^{(i)},X_t^{(i)}) =
  \frac{\pi_t(X_t^{(i)})L_{t-1}(X_t^{(i)}, X_{t-1}^{(i)})}
  {\pi_{t-1}(X_{t-1}^{(i)})K_t(X_{t-1}^{(i)}, X_t^{(i)})}
\end{equation}
If $\pi_t$ is only known up to a normalizing constant, say $\pi_t(x_t) =
\gamma_t(x_t)/Z_t$, then we can use the \emph{unnormalized} incremental weights
\begin{equation}
  w_t(X_{t-1}^{(i)},X_t^{(i)}) =
  \frac{\gamma_t(X_t^{(i)})L_{t-1}(X_t^{(i)}, X_{t-1}^{(i)})}
  {\gamma_{t-1}(X_{t-1}^{(i)})K_t(X_{t-1}^{(i)}, X_t^{(i)})}
\end{equation}
for importance sampling. Further, with the previously \emph{normalized} weights
$\{W_{t-1}^{(i)}\}_{i=1}^N$, we can estimate the ratio of normalizing constant
$Z_t/Z_{t-1}$ by
\begin{equation}
  \frac{\hat{Z}_t}{Z_{t-1}} =
  \sum_{i=1}^N W_{t-1}^{(i)}w_t(X_{t-1}^{(i)},X_t^{(i)})
\end{equation}
Sequentially, the normalizing constant between initial distribution $\pi_0$ and
some target $\pi_T$, $T\ge1$ can be estimated. See \textcite{DelMoral:2006hc}
for details on calculating the incremental weights. In practice, when $K_t$ is
invariant to $\pi_t$, and an approximated suboptimal backward kernel
\begin{equation}
  L_{t-1}(x_t, x_{t-1}) = \frac{\pi(x_{t-1})K_t(x_{t-1}, x_t)}{\pi_t(x_t)}
\end{equation}
is used, the unnormalized incremental weights will be
\begin{equation}
  w_t(X_{t-1}^{(i)},X_t^{(i)}) =
  \frac{\gamma_t(X_{t-1}^{(i)})}{\gamma_{t-1}(X_{t-1}^{(i)})}.
  \label{eq:inc_weight_mcmc}
\end{equation}

\subsection{Other sequential Monte Carlo algorithms}
\label{sub:Other sequential Monte Carlo algorithms}

Some other commonly used sequential Monte Carlo algorithms can be viewed as
special cases of algorithms introduced above. The annealed importance sampling
(\ais; \textcite{Neal:2001we}) can be viewed as \smc samplers without
resampling. Particle filters as seen in the physics and signal processing
literature, can also be interpreted as the sequential importance sampling and
resampling algorithms. See \textcite{Doucet:2011us} for a review of this topic.

\section{Basic usage}
\label{sec:Basic usage}

\subsection{Conventions}
\label{sub:Conventions}

All classes that are accessible to users are within the name space
\cppinline{vsmc}. Class names are in \cppinline{CamelCase} and function names,
free or class methods, are in \cppinline{small_cases}. In the remaining of this
guide, we will omit the \cppinline{vsmc::} name space qualifiers.

\subsection{Getting and installing the library}
\label{sub:Getting and installing the library}

The library is hosted at
GitHub\footnote{\url{https://github.com/zhouyan/vSMC}}. One can download the
stable releases\footnote{\url{https://github.com/zhouyan/vSMC/releases}} or get
the development branch from the GitHub repository. This is a header only \cpp
template library. To install the library just move the contents of the
\shinline{include} directory into a proper place, e.g.,
\shinline{/usr/local/include} on Unix-alike systems. This library requires
working \cppoo, \blas and \lapack implementations. Standard C interface headers
for the later two (\cppinline{cblas.h} and \cppinline{lapacke.h}) are
required\footnote{If \mkl is used, its \cppinline{mkl_cblas.h} and
  \cppinline{mkl_lapacke.h} headers will be used}. Intel Threading Building
Blocks\footnote{\url{https://www.threadingbuildingblocks.org}} (\tbb), Intel
Math Kernel Library\footnote{\url{https://software.intel.com/en-us/intel-mkl}}
(\mkl) and \hdf\footnote{\url{http://www.hdfgroup.org}} are optional
third-party libraries. One need to define the configuration macro
\cppinline{VSMC_HAS_TBB}, \cppinline{VSMC_HAS_MKL} and
\cppinline{VSMC_HAS_HDF5} to nonzero values before including any \vsmc headers
to make their existence known to the library, respectively.

\subsection{Concepts}
\label{sub:Concepts}

\begin{table}[t]
  \begin{tabu}{X[l]X[2l]}
    \toprule
    Concept & Class \\
    \midrule
    Weight, $\{W^{(i)}\}_{i=1}^N$           & \texttt{Weight}            \\
    State, $\{X^{(i)}\}_{i=1}^N$            & \texttt{T}, user defined   \\
    Particle, $\{W^{(i)},X^{(i)}\}_{i=1}^N$ & \texttt{Particle<T>}       \\
    Single particle, $\{W^{(i)},X^{(i)}\}$  & \texttt{SingleParticle<T>} \\
    Sampler        & \texttt{Sampler<T>}                           \\
    Initialization & \texttt{Sampler<T>::init\_type}, user defined \\
    Move           & \texttt{Sampler<T>::move\_type}, user defined \\
    \mcmc          & \texttt{Sampler<T>::mcmc\_type}, user defined \\
    Monitor        & \texttt{Monitor<T>}                           \\
    \bottomrule
  \end{tabu}
  \caption{Core concepts of the library}
  \label{tab:concepts}
\end{table}

The library is based on a few core concepts. A sampler is responsible for
running an algorithm. It is composed by a particle system and operations on it.
A particle system is formed by the states $\{X^{(i)}\}_{i=1}^N$ and weights
$\{W^{(i)}\}_{i=1}^N$. This system will also be responsible for resampling. All
user defined operations are to be applied to the whole system. These are
``initialization'' and ``moves'' which are applied before resampling, and
``\mcmc'' which are applied after resampling\footnote{These operations do not
  have to be \mcmc kernels. They can be used for any purpose that suites the
  particular algorithm.}. Most statistical inferences are done through
$\sum_{i=1}^NW^{(i)}\varphi(X^{(i)})$. This can be carried out along each
sampler iteration by a monitor. Table~\ref{tab:concepts} summarizes these
concepts and the corresponding classes in the library. Each of them are
introduced in detail in the following sections.

\subsubsection{State}
\label{ssub:State}

The library gives users the maximum flexibility of how the states
$\{X^{(i)}\}_{i=1}^N$ shall be stored and structured. Any class type with a
constructor that takes a single integer value (the number of particles) as its
argument, and a method named \cppinline{copy} is acceptable. For example,
\begin{cppcode}
  class State
  {
      public:
      State(std::size_t N);

      template <typename IntType>
      void copy(std::size_t N, IntType *src_idx)
      {
          for (std::size_t i = 0; i != N; ++i) {
              // Copy state with index src_idx[i] to index i
          }
      }
  };
\end{cppcode}
How the state values are actually stored and accessed are entirely up to the
user.

For most applications, the states can be stored within an $N$ by $d$ matrix,
where $d$ is the dimension of the state. Let $X_{ij}$ denote the value of the
state of the $i$\ith particle at coordinate $j$. In this case, the library
provides a convenient class template,
\begin{cppcode}
  template <MatrixLayout Layout, std::size_t Dim, typename T>
  class StateMatrix;
\end{cppcode}
where \cppinline{Layout} is either \cppinline{RowMajor} or
\cppinline{ColMajor}, which specifies the matrix storage layout;
\cppinline{Dim} is a non-negative integer value. If \cppinline{Dim} is zero,
then the dimension may be changed at runtime. If it is positive, then the
dimension is fixed and cannot be changed at runtime. The last template
parameter \cppinline{T} is the \cpp type of $X_{ij}$. The following constructs
an object of this class,
\begin{cppcode}
  StateMatrix<ColMajor, Dynamic, double> sm(N);
\end{cppcode}
where \cppinline{Dynamic} is just a enumerator with value zero. We can specify
the dimension at runtime through the method call \cppinline{sm.resize_dim(d)}.
Note that, if the template parameter \cppinline{Dim} is positive, then the call
results in a compile-time error. To access $X_{ij}$, one can call the method
\cppinline{sm.state(i, j)}. The method call \cppinline{sm.data()} returns a
pointer to the beginning of the matrix. If \cppinline{Layout} is
\cppinline{RowMajor}, then the method call \cppinline{sm.row_data(i)} returns a
pointer to the beginning of row $i$. If \cppinline{Layout} is
\cppinline{ColMajor}, then the method call \cppinline{sm.col_data(j)} returns a
pointer to the begninning of column $j$. These methods facilitate the
interfacing with numerical libraries, such as \blas.

The \cppinline{StateMatrix} class deliberately does not provide a
\cppinline{resize} method. There are algorithms that change the sample size
between iterations. However, such algorithms often change size through
resampling or the methods, either deterministically or stochastically. Thus it
is often necessary to make a copy of the old values or generate a new set of
values. A \cppinline{resize} method is of little use in the context of \smc
algorithms and it invites errors. These possible errors do not introduce
runtime issues such as memory leak, but they break the integrity of the data
structure statistically. An example of changing size of a sampler is provided
in section~\ref{sub:Resizing a sampler}.

\subsubsection{Weight}
\label{ssub:Weight}

The weights $\{W^{(i)}\}_{i=1}^N$ are abstracted by the \cppinline{Weight}
class. The following constructs an object of this class,
\begin{cppcode}
  Weight w(N);
\end{cppcode}
There are a few methods for accessing the weights,
\begin{cppcode*}{texcomments}
  w.ess();       // Get $\text{\normalfont\textsc{ess}} = 1/\sum_{i=1}^N(W^{(i)})^2$
  w.set_equal(); // Set $W^{(i)} = 1/N$
  w.set(v);      // Set $W^{(i)} \propto v^{(i)}$
  w.mul(v);      // Set $W^{(i)} \propto W^{(i)} v^{(i)}$
  w.set_log(v);  // Set $\log W^{(i)} = v^{(i)} + \text{const.}$
  w.add_log(v);  // Set $\log W^{(i)} = \log W^{(i)} + v^{(i)} + \text{const.}$
\end{cppcode*}
where the argument \cppinline{v} is an input iterator which can be advanced at
least $N$ times. The method call \cppinline{w.data()} returns a pointer to the
normalized weights. It is important to note that the weights are always
normalized and all mutable methods only allow access to $\{W^{(i)}\}_{i=1}^N$
as a whole.

\subsubsection{Particle}
\label{ssub:Particle}

A particle system is composed of both the state values, which is of user
defined type, say \cppinline{T}, and the weights. The following constructs an
object of class \cppinline{Particle<T>},
\begin{cppcode}
  Particle<T> particle(N);
\end{cppcode}
The method call \cppinline{particle.value()} returns the type \cppinline{T}
object, and \cppinline{particle.weight()} returns the type \cppinline{Weight}
object. They are constructed with the same integer value $N$ when the above
constructor is invoked.

As a Monte Carlo algorithm, random number generators (\rng) will be used
frequently. The user is free to use whatever \rng mechanism as they see fit.
However, one common issue encountered in practice is how to maintain
independence of the \rng streams between function calls. For example, consider
below a function that manipulates some state values,
\begin{cppcode}
  void function(double &x)
  {
      std::mt19937 rng;
      std::normal_distribution<double> rnorm;
      x = rnorm(rng);
  }
\end{cppcode}
Every call of this function will give \cppinline{x} exactly the same value.
This is hardly what the user intended. One might consider an global \rng or one
as class member data. For example,
\begin{cppcode}
  std::mt19937 rng;
  void function(double &x)
  {
      std::normal_distribution<double> rnorm;
      x = rnorm(rng);
  }
\end{cppcode}
This will work fine as long as the function is never called by two threads at
the same time. However, \smc algorithms are natural candidates to
parallelization. Therefore, the user will need to either lock the \rng, which
degenerates the performance, or construct different \rng{}s for different
threads. The later, though ensures thread-safety, has other issues. For
example, consider
\begin{cppcode}
  std::mt19937 rng1(s1); // For thread 1
  std::mt19937 rng2(s2); // For thread 2
\end{cppcode}
where the seeds $s_1 \ne s_2$. It is difficult to ensure that the two streams
generated by the two \rng{}s are independent. Common practice for parallel
\rng is to use sub-streams or leap-frog algorithms. Without going into any
further details, it is sufficient to say that this is perhaps not a problem
that most users bother to solve.

The library provides a simple solution to this issue. The method call
\cppinline{particle.rng(i)} returns a reference to an \rng that conforms to the
\cppoo uniform \rng concept. It can be called from different threads at the
same time, for example,
\begin{cppcode}
  particle.rng(i); // Call from thread i
  particle.rng(j); // Call from thread j
\end{cppcode}
If $i \ne j$, then the above calls are guaranteed to be thread-safe. If \tbb is
available to the library, then it is also thread-safe even if $i = j$. In
addition, each instance of the \rng generates independent streams. Therefore,
one can write functions that process each particle, for example,
\begin{cppcode}
  void function(std::size_t i)
  {
      auto &rng = particle.rng(i);
      // Process particle i using rng
  }
\end{cppcode}
The details of the \rng system are documented later in section~\ref{sec:Random
  number generating}.

\subsubsection{Single particle}
\label{ssub:Single particle}

It is often easier to define a function $f(X^{(i)})$ than
$f(X^{(1)},\dots,X^{(N)})$. However, \cppinline{Particle<T>} only provides
access to $\{X^{(i)}\}_{i=1}^N$ as a whole through
\cppinline{particle.value()}. To allow direct access to $X^{(i)}$, the library
uses a class template \cppinline{SingeParticle<T>}. An object of this class is
constructed from the index $i$ of the particle, and a pointer to the particle
system it belongs to, for example,
\begin{cppcode}
  SingleParticle<T> sp(i, &particle);
\end{cppcode}
or more conveniently,
\begin{cppcode}
  auto sp = particle.sp(i);
\end{cppcode}
In its most basic form, it has the following methods,
\begin{cppcode}
  sp.id();       // Get the value i that sp was constructed with
  sp.particle(); // A reference to the Particle<T> object
  sp.rng();      // => sp.particle().rng(sp.id());
\end{cppcode}
If \cppinline{T} is a subclass of \cppinline{StateMatrix}, then it has two
additional methods,
\begin{cppcode}
  sp.dim();    // => sp.particle().value().dim();
  sp.state(j); // => sp.particle().value().state(sp.id(), j);
\end{cppcode}
It is clear now that the interface of \cppinline{SingleParticle<T>} depends on
the type \cppinline{T}. Later in section~\ref{sub:Customizing SingleParticle}
we will show how to insert additional methods into this class.

\subsubsection{Sampler}
\label{ssub:Sampler}

A sampler can be constructed in a few ways,
\begin{cppcode}
  Sampler<T> sampler(N);
\end{cppcode}
constructs a sampler that is never resampled, while
\begin{cppcode}
  Sampler<T> sampler(N, Multinomial);
\end{cppcode}
constructs a sampler that is resampled every iteration, using the multinomial
method. Other resampling schemes are also possible, see
section~\ref{sec:Resampling}. Last, one can also construct a sampler that is
only resampled when $\ess < \alpha N$, $\alpha\in[0, 1]$, by the following,
\begin{cppcode}
  Sampler<T> sampler(N, Multinomial, alpha);
\end{cppcode}
In summary, if one does not tell the constructor which resampling scheme to
use, then it is assumed one does not want to do resampling. If one specify the
resampling scheme without a threshold for \ess, then it is assumed it need to
be done at every step. More advanced constructors will be discussed in
section~\ref{sec:Resampling}

The method call \cppinline{sampler.particle()} returns a reference to the
particle system. A sampler can be initialized by user defined object that is
convertible to the following type,
\begin{cppcode}
  using init_type = std::function<std::size_t(Particle<T> &, void *)>;
\end{cppcode}
For example,
\begin{cppcode}
  auto init = [](Particle<T> &particle, void *param) { /* Process particle /*};
\end{cppcode}
is a \cppoo lambda expression that can be used for this purpose. One can add it
to a sampler by calling \cppinline{sampler.init(init)}. Upon calling
\cppinline{sampler.initialize(param)}, the user defined function
\cppinline{init} will be called and the argument \cppinline{param} will be
passed to it.

Similarly, after initialization, at each iteration, the particle system can be
manipulated by users given callable objects that is convertible to the
following types,
\begin{cppcode}
  using move_type = std::function<std::size_t(std::size_t, Particle<T> &)>;
  using mcmc_type = std::function<std::size_t(std::size_t, Particle<T> &)>;
\end{cppcode}
Multiple moves can be added to a sampler. The call
\cppinline{sampler.move(move, append)} adds a \cppinline{move_type} object to
the sampler, where \cppinline{append} is a boolean value. If it is
\cppinline{false}, the call will clear any moves that were added before. If it
is \cppinline{true}, then \cppinline{move} is appended to the end of a sequence
of moves. Each move will be called one by one upon calling
\cppinline{sampler.iterate()}. A similar sequence of \mcmc moves can also be
added to a sampler. The call \cppinline{sampler.iterate()} will call user
defined moves first, then perform the possible resampling, and then the
sequence of \mcmc moves.

Note that the possible resampling will also be performed after the user defined
initialization function is called by \cppinline{sampler.initialize(param)}. And
after it, the sequence of \mcmc moves will be called. If it desired no to
perform mutations during initialization, then following can be used,
\begin{cppcode}
  sampler.init(init);
  sampler.initialize(param);
  sampler.move(move, true).mcmc(mcmc, true);
  sampler.iterate(n);
\end{cppcode}
The above snippet code also demonstrates that most methods of
\cppinline{Sampler<T>} return a reference to the sampler itself and thus method
calls can be chained. In addition, method \cppinline{sampler.iterate(n)}
accepts an optional argument that specifies the number of iterations. It is a
shortcut for
\begin{cppcode}
  for (std::size_t i = 0; i != n; ++i)
      sampler.iterate();
\end{cppcode}

\subsubsection{Monitor}
\label{ssub:Monitor}

Inferences using a \smc algorithm usually require the calculation of the
quantity $\sum_{i=1}^NW^{(i)}\varphi(X^{(i)})$ at each iteration. One can
define callable object that is convertible to
\begin{cppcode}
  using eval_type =
      std::function<void(std::size_t, std::size_t, Particle<T> &, double *);
\end{cppcode}
For example,
\begin{cppcode*}{texcomments}
  void eval(std::size_t iter, std::size_t d, Particle<T> &particle, double *r)
  {
      for (std::size_t i = 0; i != particle.size(); ++i, r += dim) {
          auto sp = particle.sp(i);
          r[0] = /* $\varphi_1(X^{(i)})$ */;
          // ...
          r[d - 1] = /* $\varphi_d(X^{(i)})$ */;
      }
  }
\end{cppcode*}
The argument \cppinline{d} is the dimension of the vector function $\varphi$.
The output is an $N$ by $d$ matrix, with each row corresponding to the value of
$\varphi(X^{(i)})$. Then one can add this function to a sampler by calling,
\begin{cppcode}
  sampler.monitor("name", d, eval);
\end{cppcode}
where the first argument is the name for the monitor, second its dimension, and
the third the evaluation function. Then after all the initialization, possible
resampling, moves and \mcmc moves are done, the sampler will calculate
$\sum_{i=1}^NW^{(i)}\varphi(X^{(i)})$. This method call has two optional
arguments. First is a boolean value \cppinline{record_only}. If it is
\cppinline{true}, it is assumed that no summation is needed. For example,
\begin{cppcode*}{texcomments}
  void eval(std::size_t iter, std::size_t d, Particle<T> &particle, double *r)
  {
      r[0] = /* $\varphi_1(\{X^{(i)}\}_{i=1}^N)$ */;
      // ...
      r[d - 1] = /* $\varphi_d(\{X^{(i)}\}_{i=1}^N)$ */;
  }
\end{cppcode*}
In this case, the monitor acts merely as a storage facility. The second
optional argument is \cppinline{stage} which specifies at which point the
monitoring shall happen. It can be \cppinline{MonitorMove}, which specifies
that the monitoring happens right after the moves and before resampling. It can
also be \cppinline{MonitorResample}, which specifies that the monitoring
happens right after the resampling and before the \mcmc moves. Last, the
default is \cppinline{MonitorMCMC}, which specifies that the monitoring happens
after everything.

The output of a sampler, together with the records of any monitors it has can
be output in plain text forms through a \cpp output stream. For example,
\begin{cppcode}
  std::cout << sampler << std::endl;
\end{cppcode}
We will see how this works later with a concrete particle filter example. If
the \hdf library is available, it is also possible to write such output to \hdf
format, for example,
\begin{cppcode}
  hdfstore(sampler, file_name, data_name);
\end{cppcode}
Details can be found in section~\ref{sub:Storing objects in hdf}.

\subsection{A simple particle filter}
\label{sub:A simple particle filter}

\subsubsection{Model and algorithm}
\label{ssub:Model and algorithm}

This is an example used in \textcite{Johansen:2009wd}. Through this example, we
will show how to re-implement a simple particle filter in \vsmc. It shall walk
one through the basic features of the library introduced above.

The state space model, known as the almost constant velocity model in the
tracking literature, provides a simple scenario. The state vector $X_t$
contains the position and velocity of an object moving in a plane. That is,
$X_t = (\xpos^t, \ypos^t, \xvel^t, \yvel^t)^T$. Imperfect observations $Y_t =
(\xobs^t, \yobs^t)^T$ of the positions are possible at each time instance. The
state and observation equations are linear with additive noises,
\begin{align*}
  X_t &= AX_{t-1} + V_t \\
  Y_t &= BX_t + \alpha W_t
\end{align*}
where
\begin{equation*}
  A = \begin{pmatrix}
    1 & \Delta & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix} \qquad
  B = \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
  \end{pmatrix} \qquad
  \alpha = 0.1
\end{equation*}
and we assume that the elements of the noise vector $V_t$ are independent
Gaussian with variance $0.02$ and $0.001$ for position and velocity,
respectively. The observation noise, $W_t$ comprises independent, identically
distributed $t$-distributed random variables with degree of freedom $\nu = 10$.
The prior at time $0$ corresponds to an axis-aligned Gaussian with variance $4$
for the position coordinates and $1$ for the velocity coordinates. The particle
filter algorithm is shown in algorithm~\ref{alg:pf}.

\begin{algorithm}[t]
  \begin{algorithmic}
    \hrule\vskip1ex
    \STATE \emph{Initialization}
    \STATE\STATESKIP Set $t\leftarrow0$.
    \STATE\STATESKIP Sample
    $\xpos^{(0,i)},\ypos^{(0,i)}\sim\calN(0,4)$ and
    $\xvel^{(0,i)},\yvel^{(0,i)}\sim\calN(0,1)$.
    \STATE\STATESKIP Weight $W_0^{(i)} \propto \exp{\ell(X_0^{(i)}|Y_0)}$ where
    $\ell$ is the likelihood function.

    \STATE \emph{Iteration}
    \STATE\STATESKIP Set $t\leftarrow t + 1$.
    \STATE\STATESKIP Sample
    \begin{align*}
      \xpos^{(t,i)}&\sim\calN(\xpos^{(t-1,i)} + \Delta\xvel^{(t-1,i)}, 0.02) &
      \xvel^{(t,i)}&\sim\calN(\xvel^{(t-1,i)}, 0.001) \\
      \ypos^{(t,i)}&\sim\calN(\ypos^{(t-1,i)} + \Delta\yvel^{(t-1,i)}, 0.02) &
      \yvel^{(t,i)}&\sim\calN(\yvel^{(t-1,i)}, 0.001)
    \end{align*}
    \STATE\STATESKIP Weight $W_t^{(i)} \propto
    W_{t-1}^{(i)}\exp{\ell(X_t^{(i)}|Y_t)}$.

    \STATE \emph{Repeat the \emph{Iteration} step until all data are processed}.
    \vskip1ex\hrule
  \end{algorithmic}
  \caption{Particle filter algorithm for the almost constant velocity model.}
  \label{alg:pf}
\end{algorithm}

\subsubsection{Implementations}
\label{ssub:Implementations}

We first show the main program.
\cppfile{pf.cpp}
A \cppinline{Sampler<PFState>} object is constructed first. Then the
initialization \cppinline{PFInit}, move \cppinline{PFMove} and a monitor
\cppinline{PFMEval} that records $\xpos^t$ and $\ypos^t$ are added to the
sampler. The monitor is named \cppinline{"pos"}. Then it is initialized with
the name of the data file \shinline{"pf.data"}, and iterated $n - 1$ times,
where $n$ is the number of data points. At last, the output is written into a
text file \shinline{"pf.out"}. Below is a short
R\footnote{\url{http://r-project.org}} script that can be used to process this
\begin{rcode}
  obs <- read.table("pf.data", header = FALSE)
  pf <- read.table("pf.out", header = TRUE)
  print(pf[1:5,])

  pdf("pf.pdf")
  plot(obs[,1], obs[,2], xlab = "X", ylab = "Y")
  lines(pf$pos.0, pf$pos.1)
  dev.off()
\end{rcode}
The \rinline{print} statement shows the first five lines of the output,
\begin{routcode}
    Size Resampled Accept.0       ESS    pos.0   pos.1
  1 1000         1        0   1.54765 -1.41510 3.03569
  2 1000         1        0 159.69800 -1.22141 3.15391
  3 1000         1        0 182.29200 -1.29763 2.95484
  4 1000         1        0  17.90400 -1.48292 3.28054
  5 1000         1        0 252.25700 -1.48763 3.43379
\end{routcode}
The column \routinline{Size} shows the sample size at each iteration. The
library does not provide direct support of changing the sample size. However,
it is possible and an example is shown in section~\ref{sec:Resampling}. The
column \routinline{Resampled} shows nonzero values if resampling were performed
and zero otherwise. For each moves and \mcmc steps, an acceptance count will be
recorded. In this particular example, it is irrelevant. Next the column
\routinline{ESS} shows the value of \ess. The last two columns show the
importance sampling estimates of the positions recorded by the monitor named
\cppinline{"pos"}. The graphical representation of the output is shown in
figure~\ref{fig:pf}.

\begin{figure}
  \includegraphics{pf}
  \caption{A simple particle system}
  \label{fig:pf}
\end{figure}

Before diving into the details of the implementation of \cppinline{PFState},
etc., we will first define a few constant. The state space is of dimension $4$.
And it is natural to use a \cppinline{StateMatrix} as the base class of
\cppinline{PFState}. We define the following constants as the indices of each
state component.
\cppfile{pf_const.hpp}

\paragraph{State: \texttt{PFState}}

As noted earlier, \cppinline{StateMatrix} will be used as the base class of
\cppinline{PFState}. Since the data will be shared by all particles, we also
store the data within this class. And methods will be provided to read the data
from an external file, and compute the log-likelihood $\ell(X^{(i)})$, which
accesses the data. Below the definition of the class \cppinline{PFState}
\cppfile{pf_state.hpp}
The method \cppinline{log_likelihood} accepts the iteration number (starting
from zero at initialization) and the particle number as its input. It returns
the value of $\ell(X^{(i)})$. The method \cppinline{read_data} read the data
input member data.

\paragraph{Initialization: \texttt{PFInit}}

The initialization step is implemented as below.
\cppfile{pf_init.hpp}
An object of this class is convertible to
\cppinline{Sampler<PFState>::init_type}. After initialization each state
component with the respective Gaussian distribution, we compute the
log-likelihood and store them in a vector. The class template
\cppinline{vsmc::Vector} is very similar to \cppinline{std::vector}. See
section~\ref{sub:Aligned memory allocation} for details. After all particles
have been initialized, we set the weights of the system.

The main method, \cppinline{operator()} calls a few other methods to perform
the tasks. Later in section~\ref{sub:Symmetric Multiprocessing} it will become
clear why we structured the implementation this way.

\paragraph{Move: \texttt{PFMove}}

The move step is similar to the initialization. The implementation is as below,
\cppfile{pf_move.hpp}

\paragraph{Monitor: \texttt{PFMEval}}

Last we define \cppinline{PFMEval}, which simply copies the values of the
positions.
\cppfile{pf_meval.hpp}

\subsection{Symmetric Multiprocessing}
\label{sub:Symmetric Multiprocessing}

The above example is implemented in a sequential fashion. However, the loops
inside \cppinline{PFInit}, \cppinline{PFMove} and \cppinline{PFMEval} clearly
can be parallelized. The library provides basic support of multicore
parallelization through its \smp module. Two widely used backends, OpenMP and
\tbb are available. Here we demonstrate how to use the \tbb backend. First we
will declare the implementation classes as subclasses as below,
\begin{cppcode}
  class PFInit : public InitializationTBB<PFState>;
  class PFMove : public MoveTBB<PFState>;
  class PFMEval : public MonitorEvalTBB<PFState>;
\end{cppcode}
And remove \cppinline{operator()} from their implementations. After these
changes, the implementation will be parallelized using \tbb. It works as if
\cppinline{InitializationTBB<PFState>} has an implementation of
\cppinline{operator()} as we did before, except it is parallelized. Now it is
clear that, method such as \cppinline{eval_pre} and \cppinline{eval_post} are
called before and after the main loop. Method \cppinline{eval_sp} is called
within the loop and it need to be thread-safe. This is the main reason we
constructed the \cppinline{NormalDistribution} objects within
\cppinline{eval_sp} instead of as member data, even though they are constructed
in exactly the same way for each particle. This is because
\cppinline{NormalDistribution::operator()} is a mutable method and thus not
thread-safe.

Apart from the three base classes we have shown here, there are also
\cppinline{InitializationOMP}, etc., for using the OpenMP backend. And
\cppinline{InitializationSEQ}, etc., for implementation without
parallelization. The later works in exactly the same way as our implementation
in the last section. It is often easier to debug a single-threaded program than
a parallelized one. And thus one may develop the algorithm with the sequential
backend and obtain optimal performance latter by only changing the name of a
few base class names. This can usually be done automatically through a build
system.

\subsubsection{Performance consideration}
\label{sub:Performance consideration}

The base classes dispatch calls to \cppinline{eval_pre}, \cppinline{eval_sp},
etc., through the virtual function mechanism. The performance impact is minimal
for \cppinline{eval_pre} and \cppinline{eval_post}, since they are called only
once in each iteration and we expect the computational cost will be dominated
by \cppinline{eval_sp} in most cases. However, the dynamic dispatch can cause
considerable performance degenerating if the cost of a single call to
\cppinline{eval_sp} is small while the number of particles is large. Modern
optimizing compilers can usually devirtualize the method calls in trivial
situations. However, it is not always possible. In this situation, the library
will need a little help from the user to make compile-time dispatch. For each
implementation class, we will declare it in the following way,
\begin{cppcode}
  class PFInit : public InitializationTBB<PFState, PFInit>;
  class PFMove : public MoveTBB<PFState, PFMove>;
  class PFMEval : public MonitorEvalTBB<PFState, PFMEval>;
\end{cppcode}
The second template argument of the base class need to be exactly the same as
the derived class. For interested users, this is called Curiously Recurring
Template Pattern%
\footnote{\url{https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern}}
(\crtp). This usage of the library's base classes also provides other
flexibility. The methods \cppinline{eval_pre} etc., can be either
\cppinline{const} or mutable. They can also be \cppinline{static}.

\section{Advanced usage}
\label{sec:Advanced usage}

\subsection{Cloning objects}
\label{sub:Cloning objects}

The \cppinline{Sampler<T>} and \cppinline{Particle<T>} objects have copy
constructors and assignment operators that behaves exactly the way as \cpp
programmers would expect. However, this is behavior is not always desired. For
example, in \textcite{stpf} a stable particle filter in high-dimensions was
developed. Without going into the details, the algorithm consists of a particle
system where each particle is itself a particle filter. And thus when
resampling the global system, the \cppinline{Sampler<T>} object will be copied,
together with all of its sub-objects. This include the \rng system within
\cppinline{Particle<T>} object. Even if the user does not use this \rng system
for random number generating within user defined operations, one of these \rng
will be used for resampling by the \cppinline{Particle<T>} object. Direct
copying these \cppinline{Sampler<T>} objects will lead to multiple filters
start to generating exactly the same random numbers in the next iteration. This
is an undesired side effects. In this situation, one can clone the sampler with
the following method,
\begin{cppcode}
  auto new_sampler = sampler.clone(new_rng);
\end{cppcode}
where \cppinline{new_rng} is a boolean value. If it is \cppinline{true}, then
an exact copy of \cppinline{sampler} will be returned, except it will have the
\rng system re-seeded. If it is \cppinline{false}, then the above call behaves
exactly the same as
\begin{cppcode}
  auto new_sampler = sampler;
\end{cppcode}
Alternatively, the contents of an \cppinline{Sampler<T>} object can be cloned
from another one by
the following method,
\begin{cppcode}
  sampler.clone(other_sampler, retain_rng);
\end{cppcode}
where \cppinline{retain_rng} is a boolean value. If it is \cppinline{true},
then the \rng system of \cppinline{other_sampler} is not copied and its own
\rng system is retained. If it is \cppinline{false}, then the above call
behaves exactly the same as
\begin{cppcode}
  sampler = other_sampler;
\end{cppcode}
The above method also supports move semantics. Similar \cppinline{clone}
methods exist for the \cppinline{Particle<T>} class.

\subsection{Customizing member types}
\label{sub:Customizing member types}

The \cppinline{Particle<T>} class has a few member types that can be replaced
by the user. If the class \cppinline{T} has the corresponding types, then the
member type of \cppinline{Particle<T>} will be replaced. For example, given the
following declarations inside class \cppinline{T},
\begin{cppcode}
  class T
  {
      public:
      using size_type = int;
      using weight_type = /* User defined type */;
      using rng_set_type = RNGSetTBB<AES256_4x32>;
      using resample_rng_type = AES256_4x32;
  };
\end{cppcode}
The corresponding \cppinline{Particle<T>::size_type}, etc., will have their
defaults replaced with the above types.

A note on \cppinline{weight_type}, it needs to provide the following method
calls,
\begin{cppcode*}{texcomments}
  w.ess();       // Get $\text{\normalfont\textsc{ess}} = 1/\sum_{i=1}^N(W^{(i)})^2$
  w.set_equal(); // Set $W^{(i)} = 1/N$
  w.resample_size(); // Get the size $N$.
  w.resample_data(); // Get a pointer to normalized weights
\end{cppcode*}
For the library's default class \cppinline{Weight}, the last two calls are the
same as \cppinline{w.size()} and \cppinline{w.data()}. However, this does not
need to be so. For example, below is the outline of an implementation of
\cppinline{weight_type} for distributed systems, assuming each computing node
has been allocated $N_r$ particles.
\begin{cppcode*}{texcomments}
  class WeightMPI
  {
      public:
      double ess()
      {
          double local = /* $\sum_{i=1}^{N_r}(W^{(i)})^2$ */;
          double global = /* Gather local from each all nodes */;
          // Broadcast the value of global

          return 1 / global;
      }

      std::size_t resample_size() { return /* $\sum N_r$ */; }

      double *resample_data()
      {
          if (rank == 0) {
              // Gather all normalized weights into a member data on this node
              // Say resample\_weight\_
              return resample_weight_.data();
          } else {
              return nullptr;
          }
      }

      void set_equal()
      {
          // Set all weights to $1 / \sum N_r$
          // Synchronization
      }
  };
\end{cppcode*}
When \cppinline{Particle<T>} performs resampling, it checks if the pointer
returned by \cppinline{w.resample_data()} is a null pointer. It will only
generate the vector \cppinline{src_idx} (see section~\ref{ssub:State}) when
this it is a non-null pointer. And then \cppinline{src_idx} is passed a pointer
to this vector into \cppinline{T::copy}. Of course, the class \cppinline{T}
also needs to provide a suitable method \cppinline{copy} that can handle the
distributed system. By defining suitable \cppinline{WeightMPI} and
\cppinline{T::copy}, the library can be extended to handle distributed systems.

\subsection{Extending \protect\spt}
\label{sub:Extending spt}

The \cppinline{SingleParticle<T>} can also be extended by the user. We have
already see in section~\ref{ssub:State} that if class \cppinline{T} is a
subclass of \cppinline{StateMatrix}, \cppinline{SingleParticle<T>} can has
additional methods to access the state. This class can be extended by defining
member class template inside class \cppinline{T}. For example, for the simple
particle filter in section~\ref{sub:A simple particle filter}, we can redefine
the \cppinline{PFState} as the following,
\cppfile{pf_state_sp.hpp}
The code looks slightly more complicated before, however, it has a few
benefits. First, we no longer need global constants such as \cppinline{PosX} to
track the index. We can access states more intuitively by calling
\cppinline{sp.pos_x()}, etc. This benefit will be much more noticeable for more
complex algorithm. Second, it allows more flexibility by allowing definition of
member method that operating on a single particle inside
\cppinline{single_particle_type}.

It is important to keep the object small and copying the object efficient. The
library will frequently pass argument of \cppinline{SingleParticle<T>} type by
value.

\section{Mathematical operations}
\label{sec:Mathemtical operations}

\subsection{Constants}
\label{sub:Constants}

\begin{table}[t]
  \begin{tabu}{X[2l]X[l]X[2l]X[l]X[2l]X[l]}
    \toprule
    Function & Value &
    Function & Value &
    Function & Value \\
    \midrule
    \texttt{pi}             & $\pi$              &
    \texttt{pi\_2}          & $2\pi$             &
    \texttt{pi\_inv}        & $1/\pi$            \\
    \texttt{pi\_sqr}        & $\pi^2$            &
    \texttt{pi\_by2}        & $\pi/2$            &
    \texttt{pi\_by3}        & $\pi/3$            \\
    \texttt{pi\_by4}        & $\pi/4$            &
    \texttt{pi\_by6}        & $\pi/6$            &
    \texttt{pi\_2by3}       & $2\pi/3$           \\
    \texttt{pi\_3by4}       & $3\pi/4$           &
    \texttt{pi\_4by3}       & $4\pi/3$           &
    \texttt{sqrt\_pi}       & $\sqrt{\pi}$       \\
    \texttt{sqrt\_pi\_2}    & $\sqrt{2\pi}$      &
    \texttt{sqrt\_pi\_inv}  & $\sqrt{1/\pi}$     &
    \texttt{sqrt\_pi\_by2}  & $\sqrt{\pi/2}$     \\
    \texttt{sqrt\_pi\_by3}  & $\sqrt{\pi/3}$     &
    \texttt{sqrt\_pi\_by4}  & $\sqrt{\pi/4}$     &
    \texttt{sqrt\_pi\_by6}  & $\sqrt{\pi/6}$     \\
    \texttt{sqrt\_pi\_2by3} & $\sqrt{2\pi/3}$    &
    \texttt{sqrt\_pi\_3by4} & $\sqrt{3\pi/4}$    &
    \texttt{sqrt\_pi\_4by3} & $\sqrt{4\pi/3}$    \\
    \texttt{ln\_pi}         & $\ln{\pi}$         &
    \texttt{ln\_pi\_2}      & $\ln{2\pi}$        &
    \texttt{ln\_pi\_inv}    & $\ln{1/\pi}$       \\
    \texttt{ln\_pi\_by2}    & $\ln{\pi/2}$       &
    \texttt{ln\_pi\_by3}    & $\ln{\pi/3}$       &
    \texttt{ln\_pi\_by4}    & $\ln{\pi/4}$       \\
    \texttt{ln\_pi\_by6}    & $\ln{\pi/6}$       &
    \texttt{ln\_pi\_2by3}   & $\ln{2\pi/3}$      &
    \texttt{ln\_pi\_3by4}   & $\ln{3\pi/4}$      \\
    \texttt{ln\_pi\_4by3}   & $\ln{4\pi/3}$      &
    \texttt{e}              & $\EE$              &
    \texttt{e\_inv}         & $1/\EE$            \\
    \texttt{sqrt\_e}        & $\sqrt{\EE}$       &
    \texttt{sqrt\_e\_inv}   & $\sqrt{1/\EE}$     &
    \texttt{sqrt\_2}        & $\sqrt{2}$         \\
    \texttt{sqrt\_3}        & $\sqrt{3}$         &
    \texttt{sqrt\_5}        & $\sqrt{5}$         &
    \texttt{sqrt\_10}       & $\sqrt{10}$        \\
    \texttt{sqrt\_1by2}     & $\sqrt{1/2}$       &
    \texttt{sqrt\_1by3}     & $\sqrt{1/3}$       &
    \texttt{sqrt\_1by5}     & $\sqrt{1/5}$       \\
    \texttt{sqrt\_1by10}    & $\sqrt{1/10}$      &
    \texttt{ln\_2}          & $\ln{2}$           &
    \texttt{ln\_3}          & $\ln{3}$           \\
    \texttt{ln\_5}          & $\ln{5}$           &
    \texttt{ln\_10}         & $\ln{10}$          &
    \texttt{ln\_inv\_2}     & $1/\ln{2}$         \\
    \texttt{ln\_inv\_3}     & $1/\ln{3}$         &
    \texttt{ln\_inv\_5}     & $1/\ln{5}$         &
    \texttt{ln\_inv\_10}    & $1/\ln{10}$        \\
    \texttt{ln\_ln\_2}      & $\ln\ln{2}$        &
    &                    &
    &                    \\
    \bottomrule
  \end{tabu}
  \caption[Mathematical constants]{Mathematical constants. Note: All functions
    are prefixed by \cppinline{const_}.}
  \label{tab:Mathematical constants}
\end{table}

The library defines some mathematical constants in the form of
\cppinline{constexpr} functions. For example, to get the value of $\pi$ with
a desired precision, one can call the following.
\begin{cppcode}
  auto pi_f = const_pi<float>();
  auto pi_d = const_pi<double>();
  auto pi_l = const_pi<long double>();
\end{cppcode}
The compiler will evaluate these values at compile-time and thus there is no
performance difference from hard-coding the constants in the program, while the
readability is improved. All defined constants are listed in
table~\ref{tab:Mathematical constants}. Note that all functions has a prefix
\cppinline{const_}, which is omitted in the table.

\subsection{Vectorized operations}
\label{sub:Vectorized operations}

\begin{table}[t]
  \begin{tabu}{X[l]X[l]X[l]X[l]}
    \toprule
    Function & Operation & Function & Operation \\
    \midrule
    \texttt{add(n, a, b, y)}    & $y = a + b$                               &
    \texttt{sub(n, a, b, y)}    & $y = a - b$                               \\
    \texttt{sqr(n, a, y)}       & $y = a^2$                                 &
    \texttt{mul(n, a, b, y)}    & $y = ab$                                  \\
    \texttt{abs(n, a, y)}       & $y = |a|$                                 &
    \texttt{fma(n, a, b, c, y)} & $y = ab + c$                              \\
    \texttt{inv(n, a, y)}       & $y = 1 / a$                               &
    \texttt{div(n, a, b, y)}    & $y = a / b$                               \\
    \texttt{sqrt(n, a, y)}      & $y = \sqrt{a}$                            &
    \texttt{invsqrt(n, a, y)}   & $y = 1 / \sqrt{a}$                        \\
    \texttt{cbrt(n, a, y)}      & $y = \sqrt[3]{a}$                         &
    \texttt{invcbrt(n, a, y)}   & $y = 1 / \sqrt[3]{a}$                     \\
    \texttt{pow2o3(n, a, y)}    & $y = a^{2/3}$                             &
    \texttt{pow3o2(n, a, y)}    & $y = a^{3/2}$                             \\
    \texttt{pow(n, a, b, y)}    & $y = a^b$                                 &
    \texttt{hypot(n, a, b, y)}  & $y = \sqrt{a^2 + b^2}$                    \\
    \texttt{exp(n, a, y)}       & $y = \EE^a$                               &
    \texttt{exp2(n, a, y)}      & $y = 2^a$                                 \\
    \texttt{exp10(n, a, y)}     & $y = 10^a$                                &
    \texttt{expm1(n, a, y)}     & $y = \EE^a - 1$                           \\
    \texttt{log(n, a, y)}       & $y = \ln(a)$                              &
    \texttt{log2(n, a, y)}      & $y = \log_2(a)$                           \\
    \texttt{log10(n, a, y)}     & $y = \log_{10}(a)$                        &
    \texttt{log1p(n, a, y)}     & $y = \ln(a + 1)$                          \\
    \texttt{cos(n, a, y)}       & $y = \cos(a)$                             &
    \texttt{sin(n, a, y)}       & $y = \sin(a)$                             \\
    \texttt{sincos(n, a, y, z)} & $y = \sin(a)$, $z = \cos(a)$              &
    \texttt{tan(n, a, y)}       & $y = \tan(a)$                             \\
    \texttt{acos(n, a, y)}      & $y = \arccos(a)$                          &
    \texttt{asin(n, a, y)}      & $y = \arcsin(a)$                          \\
    \texttt{atan(n, a, y)}      & $y = \arctan(a)$                          &
    \texttt{acos(n, a, y)}      & $y = \arccos(a)$                          \\
    \texttt{atan2(n, a, b, y)}  & $y = \arctan(a / b)$                      &
    \texttt{cosh(n, a, y)}      & $y = \cosh(a)$                            \\
    \texttt{sinh(n, a, y)}      & $y = \sinh(a)$                            &
    \texttt{tanh(n, a, y)}      & $y = \tanh(a)$                            \\
    \texttt{acosh(n, a, y)}     & $y = \mathrm{arc}\cosh(a)$                &
    \texttt{asinh(n, a, y)}     & $y = \mathrm{arc}\sinh(a)$                \\
    \texttt{atanh(n, a, y)}     & $y = \mathrm{arc}\tanh(a)$                &
    \texttt{erf(n, a, y)}       & $y = \mathrm{erf}(a)$                     \\
    \texttt{erfc(n, a, y)}      & $y = \mathrm{erfc}(a)$                    &
    \texttt{cdfnorm(n, a, y)}   & $y = 1 - \mathrm{erfc}(a / \sqrt{2}) / 2$ \\
    \texttt{lgamma(n, a, y)}    & $y = \ln\Gamma(a)$                        &
    \texttt{tgamma(n, a, y)}    & $y = \Gamma(a)$                           \\
    \bottomrule
  \end{tabu}
  \caption{Vectorized mathematical operations}
  \label{tab:Vectorized mathematical operations}
\end{table}

The library provides a set of functions for vectorized mathematical operations.
For example,
\begin{cppcode}
  std::size_t n = 1000;
  vsmc::Vector<double> a(n);
  vsmc::Vector<double> b(n);
  vsmc::Vector<double> y(n);
  // Fill vectors a and b
  add(n, a.data(), b.data(), y.data());
\end{cppcode}
performs addition for vectors. If the input $a$ and $b$ are pointers to length
$n$ arrays, and the output $y$ is a pointer to array of the same length, then
this function call compute $y_i = a_i + b_i$ for $i=1,\dots,n$. Either $a$ and
$b$ can also be scalars. For example, if $b$ is a scalar, then the operation
performed is $y_i = a_i + b$. The functions defined are listed in
table~\ref{tab:Vectorized mathematical operations}. For each function, the
first parameter is always the length of the vector $n$, and the last is a
pointer to the output $y$ (except \cppinline{sincos} which has two output
pointers $y$ and $z$). For all functions, the output is always a vector. If
there are more than one input pointer, then some of them, but not all, can be
scalars.

\section{Resampling}
\label{sec:Resampling}

The library supports resampling in a more general way than the algorithm
described in section~\ref{sec:Sequential Monte Carlo}. Recall that, given a
particle system $\{W^{(i)},X^{(i)}\}_{i=1}^N$, a new system $\{\bar{W}^{(i)},
\bar{X}^{(i)}\}_{i=1}^M$ is generated. Regardless other statistical properties,
in practice, such an algorithm can be decomposed into three steps. First, a
vector $\{r_i\}_{i=1}^N$ is generated such that $\sum_{i=1}^N r_i = M$. Then a
vector $\{a_i\}_{i=1}^M$ is generated such that, $\sum_{i=1}^M
\mathbb{I}_{\{j\}}(a_i) = r_j$. And last, set $\bar{X}^{(i)} = X^{(a_i)}$.

The first step determines the statistical properties of the resampling
algorithm. The library defines all algorithms discussed in
\textcite{Douc:2005wa}. Samplers can be constructed with builtin schemes as
seen in section~\ref{ssub:Implementations}. In addition, samplers can also be
constructed with user defined resampling operations. Below is the signature,
\begin{cppcode}
  template <typename IntType, typename RNGType>
  void resample(std::size_t M, std::size_t N, RNGType &rng,
      const double *weight, IntType *replication);
\end{cppcode}
The last parameter is the output vector $\{r_i\}_{i=1}^N$. The builtin schemes
are implemented as classes with \cppinline{operator()} conforms to the above
signature. For example, \cppinline{ResampleMultinomial} implements the
multinomial resampling algorithm.

To transform $\{r_i\}_{i=1}^N$ into $\{a_i\}_{i=1}^M$, one can call the
following function,
\begin{cppcode}
template <typename IntType1, typename IntType2>
void resample_trans_rep_index(std::size_t M, std::size_t N,
    const IntType1 *replication, IntType2 *src_idx);
\end{cppcode}
where the last parameter is the output vector $\{a_i\}_{i=1}^M$. This function
guarantees that $a_i = i$ if $r_i > 0$. However, its output may not be
optimal for all applications. The last step of a resampling operation, the
copying of particles can be the most time consuming one, especially on
distributed systems. The topology of the system will need to be taking into
consideration to achieve optimal performance. In those situations, it is best
to use \cppinline{ResampleMultinomial} etc., to generate the replication
numbers, and manually perform the rest of the resampling algorithm.

\subsection{Resizing a sampler}
\label{sub:Resizing a sampler}

Now, we provide an example of changing sampler size,
\begin{cppcode}
  // sampler is an existing Sampler<T> object
  auto N = sampler.size();
  auto &rng = sampler.particle().resample_rng();
  auto weight = sampler.particle().weight().data();
  Vector<std::size_t> rep(N);
  Vector<std::size_t> idx(M);
  ResampleMultinomial resample;
  resample(M, N, rng, weight, rep.data());
  resample_trans_rep_index(M, N, rep.data(), idx.data());
  Particle<T> particle(M);
  for (std::size_t i = 0; i != M; ++i) {
      auto sp_dst = particle.sp(i);
      auto sp_src = sampler.partice().sp(idx[i]);
      // Assuming T is a subclass of StateMatrix
      for (std::size_t d = 0; d != sp_dst.dim(); ++d)
          sp_dst.state(d) = sp_src.state(d);
  }
  // Copy other data of class T if any
  sampler.particle() = std::move(particle);
\end{cppcode}

\section{Random number generating}
\label{sec:Random number generating}

The library has a comprehensive \rng system to facilitate implementation of
Monte Carlo algorithms.

\subsection{Seeding}
\label{sub:Seeding}

The singleton class template \cppinline{SeedGenerator} can be used to generate
distinctive seed sequentially. For example,
\begin{cppcode}
  auto &seed = SeedGenerator<void, unsigned>::instance();
  RNG rng1(seed.get()); // Construct rng1
  RNG rng2(seed.get()); // Construct rng2 with another seed
\end{cppcode}
The first argument to the template can be any type. For different types,
different instances of \cppinline{SeedGenerator} will be created. Thus, the
seeds generated by \cppinline{SeedGenerator<T1>} and
\cppinline{SeedGenerator<T2>} will be independent. The second parameter is the
type of the seed values. It can be an unsigned integer type. Classes such as
\cppinline{Particle<T>} will use the generator of the following type,
\begin{cppcode}
  using Seed = SeedGenerator<NullType, VSMC_SEED_RESULT_TYPE>;
\end{cppcode}
where \cppinline{VSMC_SEED_RESULT_TYPE} is a configuration macro which is
defined to \cppinline{unsigned} by default.

One can save and set the seed generator using standard \cpp streams. For
example
\begin{cppcode}
  std::ifstream seed_txt("seed.txt");
  if (seed_txt.good())
      seed_txt >> Seed::instance(); // Read seed from a file
  else
      Seed::instance().set(101);    // The default seed
  seed_txt.close();
  // The program
  std::ofstream seed_txt("seed.txt");
  seed_txt << Seed::instance();     // Write the seed to a file
  seed_txt.close();
\end{cppcode}
This way, if the simulation program need to be repeated multiple times, each
time is will use a different set of seeds.

A single seed generator is enough for a single computer program. However, it is
more difficult to ensure that each computing node has a distinctive set of
seeds in a distributed system. A simple solution is to use the
\cppinline{modulo} method of \cppinline{SeedGenerator}. For example,
\begin{cppcode}
  Seed::instance().modulo(n, r);
\end{cppcode}
where $n$ is the number of processes and $r$ is the rank of the current node.
After this call, all seeds generated will belong to the equivalent class
$s \equiv r\mod{n}$. Therefore, no two nodes will ever generate the
same seeds.

\subsection{Counter-based \protect\rng}
\label{sub:Coutner-based RNG}

\begin{table}[t]
  \def\B{\textcolor{MRed}{\textit{B}}}
  \def\V{\textcolor{MRed}{\textit{V}}}
  \begin{tabu}{X[2l]X[l]X[l]X[l]}
    \toprule
    Class & \texttt{result\_type} & Counter bits & Key bits \\
    \midrule
    \texttt{AES128\_\B x32} & \texttt{std::uint32\_t} & $128$ & $128$ \\
    \texttt{AES128\_\B x64} & \texttt{std::uint64\_t} & $128$ & $128$ \\
    \texttt{AES192\_\B x32} & \texttt{std::uint32\_t} & $128$ & $192$ \\
    \texttt{AES192\_\B x64} & \texttt{std::uint64\_t} & $128$ & $192$ \\
    \texttt{AES256\_\B x32} & \texttt{std::uint32\_t} & $128$ & $256$ \\
    \texttt{AES256\_\B x64} & \texttt{std::uint64\_t} & $128$ & $256$ \\
    \texttt{ARS\_\B x32}    & \texttt{std::uint32\_t} & $128$ & $128$ \\
    \texttt{ARS\_\B x64}    & \texttt{std::uint64\_t} & $128$ & $128$ \\
    \texttt{Philox2x32\V}   & \texttt{std::uint32\_t} & $64$  & $64$  \\
    \texttt{Philox2x64\V}   & \texttt{std::uint64\_t} & $128$ & $128$ \\
    \texttt{Philox4x32\V}   & \texttt{std::uint32\_t} & $128$ & $128$ \\
    \texttt{Philox4x64\V}   & \texttt{std::uint64\_t} & $256$ & $256$ \\
    \texttt{Threefry2x32\V} & \texttt{std::uint32\_t} & $64$  & $64$  \\
    \texttt{Threefry2x64\V} & \texttt{std::uint64\_t} & $128$ & $128$ \\
    \texttt{Threefry4x32\V} & \texttt{std::uint32\_t} & $128$ & $128$ \\
    \texttt{Threefry4x64\V} & \texttt{std::uint64\_t} & $256$ & $256$ \\
    \bottomrule
  \end{tabu}
  \caption[Counter-based \protect\rng]{Counter-based \rng; \B: either
    \cppinline{1}, \cppinline{2}, \cppinline{4}, or \cppinline{8}; \V: either
    empty, \cppinline{SSE2}, or \cppinline{AVX2}.}
  \label{tab:Counter-based RNG}
\end{table}

The standard library provides a set of \rng classes. Unfortunately, none of
them are suitable for parallel computing, at least without considerable user
input. In addition, only the \cppinline{std::mt19937} and
\cppinline{std::mt19937_64} have both high performance and desirable
statistical properties.

The development by \textcite{Salmon:2011um} made high performance parallel \rng
much more accessible than it was before. In the author's personal opinion, it
is the most significant development for parallel Monte Carlo algorithms in
recent memory. See the paper for more details. Here, it is sufficient to
mention that, the \rng introduced in the paper use a deterministic function
$f_k$, such that, for any sequence $\{c_i\}_{i>0}$, the sequence
$\{y_i\}_{i>0}$, $y_i = f_k(c_i)$, appears as random. In addition, for $k_1 \ne
k_2$, $f_{k_1}$ and $f_{k_2}$ will generate two sequences that appear
statistically independent. Compared to more conventional \rng{}s which use
recursions $y_i = f(y_{i - 1})$, these counter-based \rng{}s are much easier to
setup in a parallelized environment.

If $c$, the counter, is an unsigned integer with $b$ bits, and $k$, the key, is
an unsigned integer with $d$ bits. Then for each $k$, the \rng has a period
$2^b$. And there can be at most $2^d$ independent streams.
Table~\ref{tab:Counter-based RNG} lists all counter-based \rng{}s implemented
in this library, along with the bits of the counter and the key. They all
conform to the \cppoo uniform \rng concept. All \rng{}s in
\textcite{Salmon:2011um} are implemented along with a few additions. Note that,
the actual period of an \rng can be longer. For example, \cppinline{Philox4x64}
has a 256-bits counter but output 64-bits integers. And thus it has a
$2^{1024}$ period. Such period length may seems very small compared to many
well known \rng{}s. For example, the famous Mersenne-Twister generator
(\cppinline{std::mt19937}) has a period $2^{19937} - 1$. However, combined with
$2^{256}$ independent streams, only the most demanding programs will find these
counter-base \rng{}s insufficient.

Note that, not all \rng{}s defined by the library is available on all
platforms. The library also defines a type alias \cppinline{RNG} which is one
of the \rng{}s listed in table~\ref{tab:Counter-based RNG}. More specifically,
if the \aesni instructions are supported,
\begin{cppcode}
  using RNG = ARS_4x32;
\end{cppcode}
otherwise if \avx{}2 instructions are supported,
\begin{cppcode}
  using RNG = Threefry4x32AVX2;
\end{cppcode}
otherwise if \sse{}2 instructions are supported,
\begin{cppcode}
  using RNG = Threefry4x32SSE2;
\end{cppcode}
and last, on all other platforms,
\begin{cppcode}
  using RNG = Threefry4x32;
\end{cppcode}
This can be changed by the configuration macro \cppinline{VSMC_RNG_TYPE}.

\subsection{Non-deterministic \protect\rng}
\label{sub:Non-deterministic RNG}

If the \rdrand instructions are supported, the library also implement three
\rng{}s, \cppinline{RDRAND16}, \cppinline{RDRAND32} and \cppinline{RDRAND64}.
They output 16-, 32-, and 64-bits random unsigned integers, respectively.

\subsection{\protect\mkl{} \protect\rng}
\label{sub:MKL RNG}

\begin{table}[t]
  \begin{tabu}{X[l]X[l]}
    \toprule
    Class & \mkl \brng \\
    \midrule
    \texttt{MKL\_MCG59}         & \texttt{VSL\_BRNG\_MCG59}         \\
    \texttt{MKL\_MT19937}       & \texttt{VSL\_BRNG\_MT19937}       \\
    \texttt{MKL\_MT2203}        & \texttt{VSL\_BRNG\_MT2203}        \\
    \texttt{MKL\_SFMT19937}     & \texttt{VSL\_BRNG\_SFMT19937}     \\
    \texttt{MKL\_NONDETERM}     & \texttt{VSL\_BRNG\_NONDETERM}     \\
    \texttt{MKL\_ARS5}          & \texttt{VSL\_BRNG\_ARS5}          \\
    \texttt{MKL\_PHILOX4X32X10} & \texttt{VSL\_BRNG\_PHILOX4X32X10} \\
    \bottomrule
  \end{tabu}
  \caption[Intel \protect\mkl{} \protect\rng]{\mkl{} \rng. Note: all
    classes can have a suffix \cppinline{_64}.}
  \label{tab:MKL RNG}
\end{table}

The \mkl library provides some high performance \rng{}s. The library implement
a wrapper class \cppinline{MKLEngine} that makes them accessible as \cppoo{}
generators. They are listed in table~\ref{tab:MKL RNG}. Note that, \mkl{}
\rng{}s performs best when they are used to generate vectors of random numbers.
These wrappers use a buffer to store such vectors. And thus they have much
bigger state space than usual \rng{}s.

\subsection{Multiple \protect\rng streams}
\label{sub:Multiple RNG streams}

Earlier in section~\ref{ssub:Particle} we introduced that
\cppinline{particle.rng(i)} returns an independent \rng instance. This is
actually done through a class template called \cppinline{RNGSet}. Three of them
are implemented in the library. They all have the same interface,
\begin{cppcode}
  RNGSet<RNG> rng_set(N); // A set of N RNGs
  rng_set.resize(n);      // Change the size of the set
  rng_set.seed();         // Seed each RNG in the set with Seed::instance()
  rng_set[i];             // Get a reference to the i-th RNG
\end{cppcode}
The first implementation is \cppinline{RNGSetScalar}. As its name suggests, it
is only a wrapper of a single \rng. All calls to \cppinline{rng_set[i]} returns
a reference to the same \rng. It is only useful when an \cppinline{RNGSet}
interface is required while the thread-safety and other issues are not
important.

The second implementation is \cppinline{RNGSetVector}. It is an array of
\rng{}s with length $N$. It has memory cost $O(N)$. Many of the counter-based
\rng{}s have small state size and thus for moderate $N$, this cost is not an
issue. The method calls \cppinline{rng_set[i]} and \cppinline{rng_set[j]}
return independent \rng{}s if $i \ne j$.

Last, if \tbb is available, there is a third implementation
\cppinline{RNGSetTBB}, which uses thread-local storage (\tls). It has much
smaller memory footprint than \cppinline{RNGSetVector} while maintains better
thread-safety. The performance impact of using \tls is minimal unless the
computation at the calling site is trivial. For example,
\begin{cppcode}
  std::size_t eval_pre(SingleParticle<T> sp)
  {
      auto &rng = sp.rng();
      // using rng to initialize state
      // do some computation, likely far more costly than TLS
  }
\end{cppcode}
The type alias \cppinline{RNGSet} is defined to be \cppinline{RNGSetTBB} if
\tbb is available. Otherwise it is defined to be \cppinline{RNGSetVector}. It
is used by the \cppinline{Particle} class template. One can replace the type of
\rng set used by \cppinline{Particle<T>} with a member type of \cppinline{T}.
For example,
\begin{cppcode}
  class T
  {
      using rng_set_type = /* User defined type */;
  };
\end{cppcode}
will make the \rng set used by \cppinline{Particle<T>} replaced by the user
defined type.

\subsection{Distributions}
\label{sub:Distributions}

\begin{table}[t]
  \begin{tabu}{X[l]X[4l]}
    \toprule
    Class & Notes \\
    \midrule
    \texttt{UniformBits} & No parameters,
    uniform on the set $\{0,\dots,2^b - 1\}$, where $b$ is the number of bits
    of the result type, which has to be an unsigned integer type. \\
    \texttt{U01}         & No parameters, uniform on $[0, 1)$ \\
    \texttt{U01CC}       & No parameters, uniform on $[0, 1]$ \\
    \texttt{U01CO}       & No parameters, uniform on $[0, 1)$ \\
    \texttt{U01OC}       & No parameters, uniform on $(0, 1]$ \\
    \texttt{U01OO}       & No parameters, uniform on $(0, 1)$ \\
    \texttt{Laplace}     & Parameters: location \texttt{a}; scale \texttt{b}\\
    \texttt{Levy}        & Parameters: location \texttt{a}; scale \texttt{b}\\
    \texttt{Pareto}      & Parameters: shape \texttt{a}; scale \texttt{b}   \\
    \texttt{Rayleigh}    & Parameters: scale \texttt{sigma}                 \\
    \bottomrule
  \end{tabu}
  \caption[Random number distributions]{Random number distributions. Note: all
    class names have a suffix \cppinline{Distribution} which is omitted in the
    table}
  \label{tab:Random number distributions}
\end{table}

The library also provides implementations of some common distributions. They
all conforms to the \cppoo random number distribution concepts. Some of them
are the same as those in the \cppoo standard library, with
\cppinline{CamelCase} names. For example, \cppinline{NormalDistribuiton} can be
used as an drop-in replacement for \cppinline{std::normal_distribuiton}. This
includes all of the continuous distributions defined in the standard library.
Their benefits compared to the standard library will be discussed later.
Table~\ref{tab:Random number distributions} lists all the additional
distributions implemented.

The last, the library also implement the multivariate Normal distribution. Its
usable is summarized by the following.
\begin{cppcode*}{texcomments}
  double mean[2] = { /* the mean vector */ };
  double cov[4] = { / * the covariance matrix */ };
  double chol[3];
  double r[2];
  // Compute the lower triangular of the Cholesky decomposition
  cov_chol(2, cov, chol);
  RNG rng;
  NormalMVDistribution<double, 2> norm2(mean, chol); // Bivariate Normal
  NormalMVDistribution<double, Dynamic> normd(2, mean, chol); // Same as above
  norm2(rng, r); // Generate a bivariate Normal
  normd(rng, r); // Same as above
\end{cppcode*}
We shall mention here that the static form, where the dimension is specified as
a template parameter is more efficient.

\subsection{Vectorized random number generating}
\label{sub:Vectorized random number generating}

The \rng{}s and distributions implemented by this library provides vectorized
operations. For example,
\begin{cppcode}
  std::size_t n = 1000;
  RNG rng;
  NormalDistribution<double> norm(0, 1);
  Vector<RNG::result_type> u(n);
  Vector<double> r(n);
  rng(n, u.data());           // Generate n random unsigned integers
  rng_rand(rng, n, u.data()); // Same as above
  norm(rng, n, r.data());     // Generate n Normal random numbers
  normal_distribution(rng, n, r.data(), 0.0, 1.0);     // Same as above
  normal_distribution(rng, n, r.data(), norm.param()); // Same as above
  rng_rand(rng, norm, n, r.data());                    // Same as above
\end{cppcode}
Note that these functions will be specialized to use \mkl routines if
\cppinline{rng} is one of the engines listed in table~\ref{tab:MKL RNG}.

\subsection{Random walk}
\label{sub:Random walk}

\section{Utilities}
\label{sec:Utilities}

The library provides some utilities for writing Monte Carlo simulation
programs. For some of them, such as command line option processing, there are
more advanced, dedicated libraries out there. The library only provides some
basic functionality that is sufficient for more simple cases.

\subsection{Aligned memory allocation}
\label{sub:Aligned memory allocation}

The standard library class \cppinline{std::allocator} is used by containers to
allocate memory. It works fine in most cases. However, sometime it is desired
to allocate memory aligned by a certain boundary. The library provides the
class template,
\begin{cppcode}
  template <typename T, std::size_t Alignment = VSMC_ALIGNMENT,
  typename Memory = AlignedMemory>
  class AlignedAllocator;
\end{cppcode}
where the configuration macro \cppinline{VSMC_ALIGNMENT} is defined to be
\cppinline{32} by default. For the requirement of the parameter type
\cppinline{Memory}, see the reference manual. It is sufficient to mention here
that the default implementation works best if \tbb is available. This class can
be used as a drop-in replacement of \cppinline{std::allocator<T>}. In fact,
this library defines a type alias \cppinline{Vector<T>} which is
\cppinline{std::vector<T, AlignedAllocator<T>>} if \cppinline{T} is a scalar
type, and \cppinline{std::vector<T>} otherwise.

\subsection{Sample covariance estimating}
\label{sub:Sample covariance estimating}

\subsection{Storing objects in \protect\hdf}
\label{sub:Storing objects in hdf}

If the \hdf library is available, it is possible to store
\cppinline{Sampler<T>} objects, etc., in the \hdf format. For example,
\begin{cppcode}
  hdf5store(sampler, "pf.h5", "sampler");
\end{cppcode}
create a \hdf file with the sampler stored as a list. In R it can be processed
as the following,
\begin{rcode}
  library(rhdf5)
  pf <- as.data.frame(h5read("pf.h5", "sampler"))
\end{rcode}
This creates a \rinline{data.frame} similar to that shown in
section~\ref{ssub:Implementations}. Other types of objects can also be store,
see the reference manual for details.

\subsection{\protect\raii classes for \protect\mkl pointers}
\label{sub:RAII classes for MKL pointers}

\begin{table}
  \begin{tabu}{X[l]X[l]}
    \toprule
    Class & \mkl pointer type \\
    \midrule
    MKLStream   & VSLStreamStatePtr \\
    MKLSSTask   & VSLSSTaskPtr      \\
    MKLConvTask & VSLConvTask       \\
    MKLCorrTask & VSLCorrTask       \\
    MKLDFTask   & DFTaskPtr         \\
    \bottomrule
  \end{tabu}
  \caption{\protect\raii classes for \protect\mkl pointers}
  \label{tab:RAII classes for MKL pointers}
\end{table}

The library provides a few classes to manage \mkl pointers. It provides
Resource Acquisition Is Initialization (\raii) idiom on top of the \mkl C
interface. For example,
\begin{cppcode}
  // VSLSSTaskPtr ptr;
  // vsldSSNewTask(&ptr, &p, &n, &xstorage, x, w, indices);
  MKLSSTask<double> task(&p, &n, &xstorage, x, w, indices);
  // vsldSSEditMoments(ptr, mean, r2m, r3m, r4m, c2m, c3m, c4m);
  task.edit_moments(mean, r2m, r3m, r4m, c2m, c3m, c4m);
  // vsldSSCompute(ptr, estimates, method);
  task.compute(estimates, method)
  // vslSSDeleteTask(&ptr);
\end{cppcode}
In the above snippets, \cppinline{MKLSSTask} manages a \cppinline{VSLSSTaskPtr}
task pointer. All C functions that operates on the pointer, is also defined as
methods in the class. Table~\ref{tab:Smart pointers for MKL} lists the classes
defined by the library and their corresponding \mkl pointers.

\subsection{Program options}
\label{sub:Program options}

The library provides some basic support of processing command line program
options. Here is a minimal example
\cppfile{program_option.cpp}
When invoked as the following,
\begin{consolecode}
  ./prg --vec 1 2 1e-1 --str "abc" --vec 8 9 --str "def hij" --n 2 4
\end{consolecode}
The console output is as the following,
\begin{consolecode}
  n: 4
  str: def hij
  vec: 1 2 0.1 8 9
\end{consolecode}
To summarize these output, the same option can be specified multiple times. If
it is a scalar option, the last one is used (\shinline{--str}, \shinline{--n}).
A string option's value can be grouped by quotes. For a vector option
(\shinline{--vec}), all values are gather together and inserted into the
vector.

\subsection{Program progress}
\label{sub:Program progress}

Sometime it is desirable to see how much progress of a program has been made.
The library provide a \cppinline{Progress} class for this purpose. Below is a
minimal example,
\cppfile{progress.cpp}
When invoked, the program output something similar the below
\begin{consolecode}
  [  4%][00:07][  49019/1000000][i = 49]
\end{consolecode}
The method call \cppinline{progress.start(n * n)} starting the printing of the
progress. The argument specifies how many iterations there will be before it is
stopped. The method call \cppinline{progress.message(ss.str())} direct the
program to print a message. This is optional. Each time after we finish $n$
iterations, we increment the progress count by calling
\cppinline{progress.increment()}. And aftre everything is finished, the method
\cppinline{progress.stop()} is called.

\subsection{x86 \protect\simd operations}
\label{sub:x86 SIMD operations}

\subsection{Timing}
\label{sub:Timing}

Performance can only be improved after it is first properly benchmarked. There
are advanced profiling programs for this purpose. However, sometime simple
timing facilities are enough. The library provides a simple class
\cppinline{StopWatch} for this purpose. As its name suggests, it works much
like a physical stop watch. Here is a simple example
\begin{cppcode}
  StopWatch watch;
  for (std::size_t i = 0; i != n; ++i) {
      // Some computation
      watch.start();
      // Computation to be benchmarked;
      watch.stop();
      // Some other computation
  }
  double t = watch.seconds(); // The time in seconds
\end{cppcode}
The above example demonstrate that timing can be accumulated between loop
iterations, function calls, etc. It shall be noted that, the time is only
accurate if the computation between \cppinline{watch.start()} and
\cppinline{watch.stop()} is non-trivial.

\printbibliography[title=\refname]

\end{document}
